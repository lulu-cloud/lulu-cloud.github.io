{"meta":{"title":"Hexo","subtitle":"","description":"","author":"lulu-cloud","url":"https://lulu-cloud.github.io","root":"/"},"pages":[],"posts":[{"title":"疯狂的横向-开题期间","slug":"开题、科研与横向","date":"2023-11-23T13:42:14.000Z","updated":"2023-11-24T03:18:04.333Z","comments":true,"path":"2023/11/23/开题、科研与横向/","link":"","permalink":"https://lulu-cloud.github.io/2023/11/23/%E5%BC%80%E9%A2%98%E3%80%81%E7%A7%91%E7%A0%94%E4%B8%8E%E6%A8%AA%E5%90%91/","excerpt":"","text":"狠狠滴看各自论文，编开题报告！！ 横向横向横向，每次会议的主题。无语辣。 听首歌，只想那种积极的，听得我爽就好，邓紫棋的《再见》","categories":[{"name":"硕士生活","slug":"硕士生活","permalink":"https://lulu-cloud.github.io/categories/%E7%A1%95%E5%A3%AB%E7%94%9F%E6%B4%BB/"}],"tags":[{"name":"吐槽","slug":"吐槽","permalink":"https://lulu-cloud.github.io/tags/%E5%90%90%E6%A7%BD/"}]},{"title":"加密流量分类-论文3:FS-Net_ A Flow Sequence Network For Encrypted Traffic Classification","slug":"加密流量分类-论文3：FS-Net_ A Flow Sequence Network For Encrypted Traffic Classification","date":"2023-08-26T13:27:14.000Z","updated":"2023-11-24T03:18:04.331Z","comments":true,"path":"2023/08/26/加密流量分类-论文3：FS-Net_ A Flow Sequence Network For Encrypted Traffic Classification/","link":"","permalink":"https://lulu-cloud.github.io/2023/08/26/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB-%E8%AE%BA%E6%96%873%EF%BC%9AFS-Net_%20A%20Flow%20Sequence%20Network%20For%20Encrypted%20Traffic%20Classification/","excerpt":"","text":"0、摘要 &emsp;&emsp;FS-Net是一个端到端的分类模型，它从原始流中学习代表性特征，然后在一个统一的框架中对它们进行分类。采用多层编码器-解码器结构，可以深入挖掘流的潜在序列特征，并引入重构机制，提高特征的有效性。 1、问题引入 &emsp;&emsp;传统的基于统计特征加上机器学习的流量分类，太依赖与专业经验，即人类的特征工程，特征工程的好坏直接影响分类性能。以往的基于DL的流量分类方法如Deep Packet:，只使用了网络流量的有效载荷进行分类，没有考虑到流量中的其他信息。因此提出基于DL的端到端的分类模型，尝试设计一种新的适合流序列特征的神经网络结构，可以直接从原始输入中学习特征，学习到的特征以真实标签为指导，从而提高性能。因此，它可以节省设计和验证功能的人力。 2、问题定义 FS-Net是基于网络流量的应用分类，即应用识别。 一个原始流量可以表示为不同的类型序列，如消息类型序列或者包长度序列，本文将一个原始流量看作包长度序列。具体的，Xp表示第p个样本的序列表示：$$X_p=[L_1^p,L_2^p,…,L_n^p)]$$其中n是Xp的长度，L~i~^p^是时间步长i的数据包值。 3、模型结构3.1总览类似于AE半监督的思想，模型由五大块组成 嵌入层 编码层 解码层 重构层 分类器 3.2 嵌入层&emsp;&emsp; 任务：将L~1~到L~n~的序列信息转化为e~1~到e~n~的向量表示。如果有K个数据，且嵌入向量的维度为d，那么K个数据经过嵌入层将转化为一个矩阵E^K*d^,矩阵E是可以在模型训练过程中训练出来的，矩阵的每一个行向量都对应着一个数据样本的嵌入向量表示。 使用嵌入向量的优点： 一些非数值(如消息类型)可以很容易地表示为数值进行计算。 向量表示丰富了一个序列中每个元素保存的信息。嵌入向量的每个维度都是影响流生成的潜在特征。同一元素在不同的序列中可能有不同的含义和方面。 模型可以学习每个元素的嵌入向量的面向任务的较优秀的向量表示，从而提高分类性能。3.3 编码层 输入为嵌入向量，输出压缩后的特征 编码采用的是堆叠的Bi-GRU神经网络模型。低层的编码器学习到局部特征，高层的编码器学习到相对全局的特征，最后将所有层的最终前向与后向的隐藏状态串联Z~e~作为编码器压缩后的特征。此时，Z~e~就包含了整个编码流程序列的双向上下文信息，将会作为分类器的输入的一部分。（既有局部的，又有全局的）3.4 解码层 解码器的结构如同编码器一样，为折叠的Bi-GRU网络结构。 输入为Z~e~，输出由两个部分组成 1.第一部分类似于编码器的输出，为解码器所有层的前向状态与后向状态的拼接，称之为，Z~d~这部分输出将会作用与最终的分类器输出的一部分。 2.第二部分则是最后一层解码器的自身输出，这部分将会送入重构层，进行重构，重构目标是还原起初的模型输入。 3.5 分类器 分类器之前，设置了Dense层对分类器的输入（即Z~e~与Z~d~向量的拼接）进行压缩，得到新的特征向量z.然而，z的维度还是太高，使用两层带Selu的激活函数的MLP对z进行降维得到Z~c~,降维过后能有效避免过拟合问题。公式中的W1，b1,b2都是可以学习的参数。 输入为Z~c~，经过softmax分类器，得到预测标签A^-^，与真实标签A之间构造一个交叉熵损失L~C~ 在重构器后面，解码器中的Bi-GRU经过重构，输出的L~i^~与原始的输入特征L~i~之间可以构造另外一个交叉熵损失L~R~ 因此，最终的损失函数$$L=L_C+αL_R$$α是超参数。 4、实验 实验设置：以报文长度序列作为FS-Net的输出，嵌入向量维度d设置为128，GRU的隐藏状态维度也是128，α设置为1，dropout设置为0.3，Adam优化器的lr设置为0.0005 与其他模型结果实验对比的结论：加密流分类任务中，报文长度比消息类型更具有代表性。主要原因可能是[11]发现的不同应用程序的消息类型序列高度重叠。有更多的信息蕴含在包长度集合中而不是消息类型的集合中。 对FS-Net的一些分析： 摒弃解码器层、重构层和重构损失，即只将基于编码器的特征向量Z~e~传递到密集层进行分类。该变体称为FS-ND.此时FS-Net与其变体FS-ND的默认输入仍旧为包长度序列（The packet length sequence）。 个人感觉这种变体特别像BERT，BERT就是只使用了Transformer的编码器结构，经历预训练后，在诸多下游任务中均获得了不错的效果。当然，BERT是有MLM与NSP的预训练任务的，而此处的FS-ND貌似并没有提及，只是单纯砍掉了解码器与重构器那一部分。 因为传统的消息类型马尔可夫方法(FoSM、SOCRT、SOB)以消息类型序列（The message type sequences）作为输入。为了便于比较，FS-Net和FS-ND也结合消息类型序列进行测试，对应的方法记为FS-Net- s和FS-ND- s。 采用多属性序列(消息类型序列和报文长度序列)来提高性能。即同时关注包长度序列（The packet length sequence）与消息类型序列（The message type sequences），这两种不同的模型被称为FS-Net-SL和FS-ND-SL。 结果分析： 重构机制（即包含解码层、重构层）有用，提高分类性能。与不同序列比较，FS-Net的FTF性能始终优于FS-ND，提高了0.01左右。利用重构机制，引导从编码器学习到的特征存储更丰富的信息。 重构机制有用，但是对比FS-ND提示不大，并且加了那么多结构，有点不太划算。变体模型FS-ND也优于现有的模型，而且FS-Net和FS-ND之间的性能差距不大。然而，FS-ND模型比FS-Net需要更少的层，可以更快地训练。 报文长度序列的信息比消息类型序列的信息更丰富。消息类型序列的信息几乎被合并到包长度序列中。从FS-Net到FS-Net- sl的改进不显著(如FTF为0.0005)。FSND和FS-ND-SL之间也存在类似的现象。 调参分析： GRU的隐藏状态维度：太大，模型冗余，过拟合的同时容易从噪声中学习无用信息；太小，不足以提取数据的隐藏特征。研究中设置为128。 超参数α：建议α值设为[0.125,2]。5、总结与思考 模型结构，类似与NLP中的Seq2Seq结构，可否在中间的编码器与解码器之间照葫芦画瓢加上Attention机制来进一步优化捏？ 去除解码器与重构器，模型复杂度减少，并且实验证明在数据集上的表现FS-ND也跟FS-Net差之无几，能否在FS-ND上做出改进，使之效率与复杂度要比现在的模型好。","categories":[{"name":"加密流量分类","slug":"加密流量分类","permalink":"https://lulu-cloud.github.io/categories/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"论文","slug":"论文","permalink":"https://lulu-cloud.github.io/tags/%E8%AE%BA%E6%96%87/"}]},{"title":"加密流量分类-论文2:Deep Packet_ A Novel Approach For Encrypted Traffic Classification Using Deep Learning","slug":"加密流量分类-论文2：Deep Packet_ A Novel Approach For Encrypted Traffic Classification Using Deep Learning","date":"2023-08-25T13:27:14.000Z","updated":"2023-11-24T03:18:04.338Z","comments":true,"path":"2023/08/25/加密流量分类-论文2：Deep Packet_ A Novel Approach For Encrypted Traffic Classification Using Deep Learning/","link":"","permalink":"https://lulu-cloud.github.io/2023/08/25/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB-%E8%AE%BA%E6%96%872%EF%BC%9ADeep%20Packet_%20A%20Novel%20Approach%20For%20Encrypted%20Traffic%20Classification%20Using%20Deep%20Learning/","excerpt":"","text":"0、摘要&emsp;&emsp;论文提出的方案称为“深度包”(deep packet)，可以处理网络流量分类为主要类别(如FTP和P2P)的流量表征，以及需要终端用户应用程序(如BitTorrent和Skype)识别的应用程序识别。与现有的大多数方法不同，深度报文不仅可以识别加密流量，还可以区分VPN网络流量和非VPN网络流量。网络架构基于CNN与SAE，能同时进行应用识别与流量类型的分类任务。 1、介绍&emsp;&emsp;准确的流量分类已成为提供适当的服务质量(quality of service, QoS)、异常检测等高级网络管理任务的先决条件之一。流量分类在与网络管理相关的学术界和工业界都引起了极大的兴趣。 &emsp;&emsp;本文贡献： 在Deep Packet中，不需要专家来提取与网络流量相关的特征。这种方法省去了查找和提取特征的繁琐步骤。（只要是基于DL的方法都能做到这一点） Deep Packet可以在两个粒度级别(应用程序识别和流量表征)上识别流量，并获得最先进的结果。 深度数据包可以准确地分类最难的一类应用程序，已知是P2P。 2、相关工作&emsp;&emsp;等于是一个综述，概览了之前流量分类的一些方法以及它的适用性与优缺点。可以参考论文解读1 Port-based approach（基于端口）：提取过程简单，端口号不受加密方案的影响。然而，端口混淆、网络地址转换(NAT)、端口转发、协议嵌入和端口随机分配的普遍存在大大降低了这种方法的准确性，目前已经不适用。 Payload Inspection Techniques（基于有效载荷）:即深度包检测（DPI）。 Statistical and machine learning approach（基于统计特征+机器学习方法）：这些方法依赖于流量的统计或时间序列特性，能够处理加密和未加密的流量。 &emsp;&emsp;总之，以前的方法，特征提取阶段依赖于人类的特征工程，耗时、昂贵且出错率高。 3、深度学习背景&emsp;&emsp;依旧是综述，关于神经网络的。这里主要介绍了两种神经网络结构。 3.1 自编码器（Autoencoder，AE）&emsp;&emsp;AE是一种无监督框架。考虑一个训练集{x1, x2，…， xn}其中对于每个训练数据我们有xi∈Rn。自编码器目标定义为yi = xi，对于i∈{1,2，…， n}，即网络的输出等于输入。自动编码器试图学习数据集的压缩表示，即将高维数据通过编码器降维，然后降维后的数据通过解码器升维，输出尽量与输入相同。这样。降维后的数据则包含了原始输入数据的信息。一般地，编码器与解码器的结构都是对称的。&emsp;&emsp;在实践中，为了获得更好的性能，一般使用堆栈式自动编码器(SAE)。将多个自动编码器堆叠起来，每个编码器的输出都是连续层的输入，而连续层本身就是一个自动编码器。堆叠式自动编码器的训练过程采用贪婪的分层方式完成。首先，该方法训练网络的每一层，同时冻结其他层的权值。在训练完所有层之后，为了得到更准确的结果，对整个神经网络进行微调。在微调阶段，利用反向传播算法调整各层权重。此外，对于分类任务，可以在最后一层应用额外的softmax层。 3.2 卷积神经网络(Convolutional Neural Network, CNN) 卷积：进行特征抽取 池化：聚合低级特征，获得局部不变性，并且能降低网络训练与测试的参数量。&emsp;&emsp;一维卷积神经网络（1D-CNNs）可以捕获网络数据包中相邻字节之间的空间依赖关系，从而找到每一类协议/应用程序的区别模式，从而对流量进行准确的分类。4、方法4.1 数据集&emsp;&emsp;ISCX VPN-nonVPN：该数据集实在数据链路层捕获的，因此，每个数据包都包含一个以太网报头、一个IP数据报报头、一个TCP/UDP报头。 4.2 预处理 删除以太网报头 将UDP报头填充0至20字节长度（TCP通常具有20字节长度的报头，而UDP具有8字节长度的报头。为了使传输层的段一致，在UDP段的报头末尾注入0，使它们的长度与TCP报头相等） 屏蔽IP数据报报头的IP 删除不相关的数据包，例如没有负载的数据包（TCP握手时SYN、ACK设置为1以及FIN设置为1的数据包）或者DNS数据段（将url转为IP地址的） 将原始数据包转为字节向量 截断超过1500的向量，不足1500长度的填充0 将向量的每个元素除以255来规范化字节向量 针对样本不均衡问题，对样本更多的类进行欠采样，直到类相对平衡。4.3 网络架构 关于SAE的部分：由五个全连接层（FC）,分别由400、300、200、100和50个神经元组成。为防止过拟合问题，每层后采用dropout技术，dropout率为0.05。针对应用识别和流量表征任务，在SAE的最后一层，分别添加了一个包含17个神经元和12个神经元的softmax分类器。 关于CNN的部分：包括两个连续的卷积层，然后是池化层。将二维张量压缩为一维矢量，并将其送入三层全连接神经元网络，该网络采用dropout技术以避免过拟合。最后，将类似于SAE架构的softmax分类器应用于分类任务。CNN的超参数如下：5、实验 对于CNN的调参，此处改变了两个卷积层的滤波器大小、滤波器数量和步幅。总共评估了116个应用识别和交通表征任务的加权平均F1分数模型。通过结果得出如下结论：对于流量分类任务，无法选择最优模型，因为“最优模型”的定义是不明确的，而且模型的精度和它的复杂性(即训练速度和测试速度)之间存在权衡。 增加神经网络的复杂度并不一定会带来更好的性能。可能的原因有：&emsp;&emsp;一个复杂的模型在训练阶段更容易遇到梯度消失问题，从而导致模型的欠拟合。&emsp;&emsp; 一个学习模型变得更复杂，而训练数据的大小保持不变，就会出现过拟合问题。 该工作与Wang W, Zhu M, Wang J, Zeng X, Yang Z (2017)End-to-end encrypted traffic classification with one-dimensional convolution neural networks. In: Intel-ligence and Security Informatics (ISI), 2017 IEEE International Conference on, IEEE. 的方法类似，但Wang等人在流量表征的任务上获得了100%的精度，可能的原因是预处理过程中没有屏蔽IP地址字段，导致模型仅仅用IP地址这一特征来进行分类。 6、总结","categories":[{"name":"加密流量分类","slug":"加密流量分类","permalink":"https://lulu-cloud.github.io/categories/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"论文","slug":"论文","permalink":"https://lulu-cloud.github.io/tags/%E8%AE%BA%E6%96%87/"}]}],"categories":[{"name":"硕士生活","slug":"硕士生活","permalink":"https://lulu-cloud.github.io/categories/%E7%A1%95%E5%A3%AB%E7%94%9F%E6%B4%BB/"},{"name":"加密流量分类","slug":"加密流量分类","permalink":"https://lulu-cloud.github.io/categories/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"吐槽","slug":"吐槽","permalink":"https://lulu-cloud.github.io/tags/%E5%90%90%E6%A7%BD/"},{"name":"论文","slug":"论文","permalink":"https://lulu-cloud.github.io/tags/%E8%AE%BA%E6%96%87/"}]}