<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"lulu-cloud.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="lulu-cloud的个人GitHub博客">
<meta property="og:type" content="website">
<meta property="og:title" content="lulu-cloud">
<meta property="og:url" content="https://lulu-cloud.github.io/page/3/index.html">
<meta property="og:site_name" content="lulu-cloud">
<meta property="og:description" content="lulu-cloud的个人GitHub博客">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="luluX">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://lulu-cloud.github.io/page/3/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>lulu-cloud</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">lulu-cloud</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lulu-cloud.github.io/2022/11/18/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB-%E8%AE%BA%E6%96%8711%20FlowPic_%20A%20Generic%20Representation%20for%20Encrypted%20Traffic%20Classification%20and%20Applications/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/ava.jpg">
      <meta itemprop="name" content="luluX">
      <meta itemprop="description" content="lulu-cloud的个人GitHub博客">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="lulu-cloud">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/18/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB-%E8%AE%BA%E6%96%8711%20FlowPic_%20A%20Generic%20Representation%20for%20Encrypted%20Traffic%20Classification%20and%20Applications/" class="post-title-link" itemprop="url">加密流量分类-论文11: FlowPic_ A Generic Representation for Encrypted Traffic Classification and Applications</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-11-18 21:27:14" itemprop="dateCreated datePublished" datetime="2022-11-18T21:27:14+08:00">2022-11-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-11-24 21:43:54" itemprop="dateModified" datetime="2023-11-24T21:43:54+08:00">2023-11-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/" itemprop="url" rel="index"><span itemprop="name">科研</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB/" itemprop="url" rel="index"><span itemprop="name">加密流量分类</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="0、摘要"><a href="#0、摘要" class="headerlink" title="0、摘要"></a>0、摘要</h1><p>&emsp;&emsp;利用了流中与<strong>时间</strong>相关和与大小相关的特性，将基本流量数据转换为直观的图片FlowPic，然后使用已知的图像分类深度学习技术cnn来识别流量类别(浏览、聊天、视频等)和正在使用的应用程序。<strong>但是不是使用负载数据形成的特征图。</strong></p>
<h1 id="1、介绍"><a href="#1、介绍" class="headerlink" title="1、介绍"></a>1、介绍</h1><p>&emsp;&emsp;对于每个流，我们的方法根据数据包大小和数据包到达时间创建一个图像，我们称之为FlowPic。</p>
<ul>
<li>不依赖于数据包有效负载内容，因此不会侵犯隐私</li>
<li>存储需求非常小，分类速度块，近乎实时，可以进行在线的流量分类</li>
</ul>
<h1 id="2、数据集介绍"><a href="#2、数据集介绍" class="headerlink" title="2、数据集介绍"></a>2、数据集介绍</h1><ul>
<li><p>数据集：ISCX VPN-nonVPN、ISCX Tor-nonTor、作者团队自己捕获的数据集（命名为TAU）</p>
</li>
<li><p>分类标签类别：</p>
<ol>
<li><p>VoIP</p>
</li>
<li><p>Video</p>
</li>
<li><p>Chat</p>
</li>
<li><p>File Transfer</p>
</li>
<li><p>Browsing</p>
</li>
</ol>
</li>
</ul>
<p>因此，对于五个类别，三种加密技术(非VPN、VPN、Tor)，相当于15种流量。</p>
<blockquote>
<p>显然这是关于流量类型识别</p>
</blockquote>
<h2 id="2-1-数据处理"><a href="#2-1-数据处理" class="headerlink" title="2.1 数据处理"></a>2.1 数据处理</h2><p>&emsp;&emsp;主要是写作者自己数据的收集的一些细节。</p>
<h2 id="2-2-数据增强"><a href="#2-2-数据增强" class="headerlink" title="2.2 数据增强"></a>2.2 数据增强</h2><ul>
<li><p>单向流分大小相等的块，实验中为每隔60s分为一个块</p>
</li>
<li><p>但是为了进行数据增强，就将两个块之间进行重叠，重叠时间设置为45秒，这样块与块之间的间隔为15秒</p>
<blockquote>
<p>数据扩充过程是在将所有会话分割为一个训练集和一个测试集之后进行的，确保训练块和测试块之间在单个会话中没有重叠</p>
</blockquote>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242127932.png" alt="image-20221118194010907"></p>
<p>（数据增广后的每个类别的样本数目）</p>
<h2 id="2-3-敏感性分析"><a href="#2-3-敏感性分析" class="headerlink" title="2.3 敏感性分析"></a>2.3 敏感性分析</h2><p>关于数据增强是否真的有效？块长大小为多少合适？</p>
<p>结论：</p>
<ol>
<li>在个别的流量类型里，数据增强效果不明显</li>
<li><p>60s的块大小最合适</p>
<h1 id="3-构建图像"><a href="#3-构建图像" class="headerlink" title="3 构建图像"></a>3 构建图像</h1></li>
</ol>
<h2 id="3-1-构建FlowPic"><a href="#3-1-构建FlowPic" class="headerlink" title="3.1 构建FlowPic"></a>3.1 构建FlowPic</h2><ul>
<li><p>提取每个单向流中的每个数据包的两个特征<strong>IP包大小</strong>、<strong>到达时间</strong></p>
</li>
<li><p>构建一个基于流的二维直方图的图像,该图像可以被视为负载大小分布(PSD)</p>
<ul>
<li><p>X轴为包的到达时间，Y轴为包的大小</p>
<blockquote>
<p>绝大多数包的大小都不超过1500字节(这是以太网MTU值)，将y轴限制在1到1500之间。</p>
<p>对于x轴，将2d直方图设置为正方形图像。为此，我们将所有到达时间值标准化为0到1500之间(即60秒映射为1500)</p>
<ul>
<li>生成1500x1500的直方图，直方图命名为FlowPic，存储在矩阵当中，作为模型输入</li>
</ul>
</blockquote>
</li>
</ul>
</li>
</ul>
<h2 id="3-2-FlowPic分析"><a href="#3-2-FlowPic分析" class="headerlink" title="3.2 FlowPic分析"></a>3.2 FlowPic分析</h2><p>&emsp;&emsp;这里说了作者在对生成FlowPic的一点分析，从而说明FlowPic能反映出网络流通特征复杂，使用深度神经网络模型进行特征提取并分类是很有必要的。</p>
<ul>
<li>分析1：在不同应用下，对视频流的分析：</li>
</ul>
<p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242127831.png" alt="image-20221118195503724"></p>
<blockquote>
<p> 不用应用下的流量类型表现不同特性，例如，Netflix传输的数据包大小几乎是固定的，而Skype、Facebook和谷歌Hangout等应用程序传输的大小分布广泛。并且，视频流不仅限于显示元素，还包括行为与VoIP相同的音频流，以及看起来像聊天传输的用于协调和控制的小数据包流。相比之下，例如在Skype上，视频流和音频流是分开的。</p>
</blockquote>
<ul>
<li><p>分析2：加密技术对流量类别的流行为的影响：</p>
<p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242127589.png" alt="image-20221118195738482"></p>
<p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242127465.png" alt="image-20221118195756083"></p>
<p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242127413.png" alt="image-20221118195807254"></p>
</li>
</ul>
<blockquote>
<p>在不同的加密技术之间，有些类别的flowpic行为完全不同</p>
</blockquote>
<ul>
<li><p>分析3：Tor的加密技术下，Tor流量的包的大小分布比较离散，从图中可以看出来，与非vpn流量中的许多包大小不同。</p>
<p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242127818.png" alt="image-20221118200339300"></p>
</li>
</ul>
<h1 id="4-卷积神经网络结构设计"><a href="#4-卷积神经网络结构设计" class="headerlink" title="4 卷积神经网络结构设计"></a>4 卷积神经网络结构设计</h1><ul>
<li><p>输入：二维1500x1500图像</p>
</li>
<li><p>输出：2或者流量类别（2是判定是否为NonVPN）</p>
<p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242127129.png" alt="image-20221118200711631"></p>
</li>
</ul>
<p><strong>延迟分析</strong>：TBS +TFC +TML</p>
<ul>
<li><p>TBS是自定义块大小(15、30或60秒)</p>
</li>
<li><p>TFC是FlowPic构建时间</p>
</li>
<li><p>TML是执行分类的CNN运行时间。</p>
<p>&emsp;  &emsp;实验中，我们发现TFC和TML都是0.1 s，与块大小相比可以忽略不计，故可以满足在线分类要求。</p>
<h1 id="5、实验"><a href="#5、实验" class="headerlink" title="5、实验"></a>5、实验</h1></li>
</ul>
<h2 id="5-1-处理样本不平衡问题"><a href="#5-1-处理样本不平衡问题" class="headerlink" title="5.1 处理样本不平衡问题"></a>5.1 处理样本不平衡问题</h2><p>方法：过采样、欠采样</p>
<h3 id="5-1-1-多类分类情况"><a href="#5-1-1-多类分类情况" class="headerlink" title="5.1.1 多类分类情况"></a>5.1.1 多类分类情况</h3><ol>
<li><p>流量类型分类（Traffic categorization）：对于三种数据集（非VPN、VPN和Tor）合并其中相同类型的，而不考虑加密技术，动机是研究加密技术如何影响流量行为。</p>
</li>
<li><p>加密技术分类：即3分类，识别出是否为非VPN、VPN和Tor三种的某一种流量。</p>
</li>
<li><p>应用识别：使用创建的数据集，在<strong>VoIP类型</strong>与<strong>视频类型</strong>下捕获10个应用程序的三种加密方式（非VPN、VPN、Tor）的流量。</p>
</li>
</ol>
<h3 id="5-1-2-一对多的分类情况"><a href="#5-1-2-一对多的分类情况" class="headerlink" title="5.1.2 一对多的分类情况"></a>5.1.2 一对多的分类情况</h3><p>&emsp;&emsp;为3种加密技术构建类与所有数据集:非VPN、VPN(针对所有类，除了browse)和TOR，以及合并数据集。对于每种加密技术，每个流类别合并数据集包含相同数量的会话。</p>
<blockquote>
<p>训练测试集比例是 9:1</p>
</blockquote>
<ul>
<li><p>Wang等人<a href="[加密流量分类-论文4Endtoend Encrypted Traffic Classification with One-dimensional Convolution Neural Networks_烟玉蓝田的博客-CSDN博客](https://blog.csdn.net/qq_45125356/article/details/126925196?spm=1001.2014.3001.5501">link</a>)使用每个流的前784字节对ISCX VPN-非VPN数据集上的流量进行分类，并使用不同的表示方法分别对非VPN和VPN流量实现了83.0%和98.6%的最佳准确性。但Wang的实验没有包括浏览类别，因为很难将其与其他类别区分开来。从上图的混淆矩阵可以看出，，难以区分浏览和聊天是导致准确度下降的主要原因。</p>
<p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242127937.png" alt="image-20221118202550257"></p>
</li>
<li><p>与其他方法的对比</p>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242127191.png" alt="image-20221118203401553"></p>
<blockquote>
<p>还有很多的实验结果：比如未知流量识别、加密技术分类、应用分类，不一一列举。</p>
</blockquote>
<h1 id="5、总结与思考"><a href="#5、总结与思考" class="headerlink" title="5、总结与思考"></a>5、总结与思考</h1><ul>
<li><p>亮点：FlowPic的图生成很好，模型分类快，能进行在线分类，不依赖于双向流信息</p>
<blockquote>
<p>只考虑时间特征，可以结合空间特征，构造常规的有效载荷流量图，然后进行结合着进行分类？</p>
</blockquote>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lulu-cloud.github.io/2022/11/11/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB-%E8%AE%BA%E6%96%8710%EF%BC%9AGlobal-Aware%20Prototypical%20Network%20for%20Few-Shot%20Encrypted%20Traffic%20Classification/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/ava.jpg">
      <meta itemprop="name" content="luluX">
      <meta itemprop="description" content="lulu-cloud的个人GitHub博客">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="lulu-cloud">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/11/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB-%E8%AE%BA%E6%96%8710%EF%BC%9AGlobal-Aware%20Prototypical%20Network%20for%20Few-Shot%20Encrypted%20Traffic%20Classification/" class="post-title-link" itemprop="url">加密流量分类-论文10: Global-Aware Prototypical Network for Few-Shot Encrypted Traffic Classification</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-11-11 21:27:14" itemprop="dateCreated datePublished" datetime="2022-11-11T21:27:14+08:00">2022-11-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-11-24 21:43:51" itemprop="dateModified" datetime="2023-11-24T21:43:51+08:00">2023-11-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/" itemprop="url" rel="index"><span itemprop="name">科研</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB/" itemprop="url" rel="index"><span itemprop="name">加密流量分类</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="0、摘要"><a href="#0、摘要" class="headerlink" title="0、摘要"></a>0、摘要</h1><ul>
<li><p>现在大部分对于小样本学习的方法都是基于度量(metric learning)解决，但是这些方法只考虑到了流量的局部信息，故对最终的分类性能有一定影响</p>
</li>
<li><p>本文提出的GP-Net，<strong>考虑负载序列的两个字节之间的关系，利用字节之中的关系聚合流量输入的全局信息</strong></p>
</li>
</ul>
<blockquote>
<p>少样本学习是元学习的在监督学习领域的应用，可以参考<a href="[Few-shot learning（少样本学习）入门 - 知乎 (zhihu.com">link</a>](<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/156830039">https://zhuanlan.zhihu.com/p/156830039</a>))</p>
</blockquote>
<h1 id="1、概念介绍"><a href="#1、概念介绍" class="headerlink" title="1、概念介绍"></a>1、概念介绍</h1><h2 id="1-1-基于metric的少样本学习的方法"><a href="#1-1-基于metric的少样本学习的方法" class="headerlink" title="1.1 基于metric的少样本学习的方法"></a>1.1 基于metric的少样本学习的方法</h2><p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242125077.png" alt="img"></p>
<ul>
<li>过去使用一维卷积神经网络作为编码器解码器提取流量特征的方法，如<a href="[加密流量分类-论文6：Learning to Classify A Flow-Based Relation Network for Encrypted Traffic Classification_烟玉蓝田的博客-CSDN博客](https://blog.csdn.net/qq_45125356/article/details/127142284?spm=1001.2014.3001.5502">RBRN</a>)因为卷积核大小的限制，难以提取整个流量的<strong>全局信息</strong>，因此导致后续计算相似度时，不够精确。</li>
</ul>
<h2 id="1-4-文章核心观点引入"><a href="#1-4-文章核心观点引入" class="headerlink" title="1.4 文章核心观点引入"></a>1.4 文章核心观点引入</h2><ul>
<li><p>论文模型优势：在新流量类型样本不足的情况下学习更好的表示方法</p>
</li>
<li><p>四大模块：</p>
<ul>
<li><p>流量归一化：将原始流量（输入是流量的有效载荷信息）转为图片</p>
</li>
<li><p>全局感知表示：基于自注意力的思想，<strong>并且对负载序列中字节位置信息进行建模</strong>，克服自注意力机制中的位置不可知的缺陷，这样就能聚合流量的全局信息. </p>
<blockquote>
<p>所谓全局感知，其实就是引入了自注意力机制而已</p>
</blockquote>
</li>
<li><p>嵌入生成器：卷积操作，因为前面的全局感知，使得这里的卷积不同于以前论文方法的卷积，<font color="red">全局而不局限</font></p>
</li>
<li><p>计算相似度模块：与以前方法类似。</p>
<blockquote>
<p>通篇下来就是<font color="red">全局</font>两个字</p>
</blockquote>
</li>
</ul>
<h1 id="2、初步知识"><a href="#2、初步知识" class="headerlink" title="2、初步知识"></a>2、初步知识</h1><h2 id="2-1-元学习概念"><a href="#2-1-元学习概念" class="headerlink" title="2.1 元学习概念"></a>2.1 元学习概念</h2></li>
</ul>
<p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242125678.png" alt="img"></p>
<p>&emsp;&emsp;元学习概念：与传统的机器学习不同，元学习的基本单元是一个任务而不是一个训练示例。元学习的主要目标是从元训练任务中获取通用的元知识，并将其用于只需少量样本的元测试任务的快速学习。如上图：训练任务与测试任务是不相关的，用不同颜色与形状表示出来，元学习期待从完成元任务中学习到的知识能很好地迁移到待试验数据上。</p>
<h2 id="2-2-问题定义"><a href="#2-2-问题定义" class="headerlink" title="2.2 问题定义"></a>2.2 问题定义</h2><p>&emsp;&emsp;假定两个流量数据集，都是有标签的，定义为：</p>
<script type="math/tex; mode=display">
D^{tr}=\{(x_1^{tr},y_1^{tr}),(x_1^{tr},y_1^{tr}),···，(x_K^{tr},y_K^{tr}),\}</script><script type="math/tex; mode=display">
其中，x_i^{tr}∈R^d，y_i^{tr}∈\{1,2,···，C\}</script><script type="math/tex; mode=display">
D^{test}=\{(x_1^{test},y_1^{tr}),(x_1^{test},y_1^{test}),···，(x_K^{test},y_K^{test}),\}</script><script type="math/tex; mode=display">
其中，x_i^{test}∈R^d，y_i^{tr}∈\{C+1,···,C+N\}</script><p>&emsp;&emsp;意味着D<sup>tr</sup>中有C个类别的流量，并且每一种类的流量都有一定的样本，但是，在D<sup>test</sup>中，样本数量非常少，并且类别都是D<sup>tr</sup>中没有的。</p>
<p>&emsp;&emsp;将训练集与测试集中的任务定义为：</p>
<script type="math/tex; mode=display">
\tau=\{\tau_A^{tr},\tau_B^{tr},\tau_C^{tr},···\}</script><p>每一个元素代表一个任务，是二元分类，如上图，都由支持集(support set)与查询集(query set)组成，叫法这么叫而已，其实就是训练集与验证集。</p>
<p>&emsp;&emsp;支持集与查询集的形成遵循N-way、K-shot原则，即N个流量类型，每个类型抽k个样本。这样在测试任务中，即使测试任务的支持集很小，但是在元学习的表现下，仍然有不错的泛化性。</p>
<h1 id="3-GP-Net"><a href="#3-GP-Net" class="headerlink" title="3 GP-Net"></a>3 GP-Net</h1><h2 id="3-1-概览"><a href="#3-1-概览" class="headerlink" title="3.1 概览"></a>3.1 概览</h2><p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242125616.png" alt="img"></p>
<h2 id="3-2-流量归一化模块"><a href="#3-2-流量归一化模块" class="headerlink" title="3.2 流量归一化模块"></a>3.2 流量归一化模块</h2><p>&emsp;&emsp;经典三大步：分流、地址匿名、转为图片形式</p>
<ul>
<li><p>分流：这里没说是单向流还是双向会话流，使用工具SplitCap</p>
</li>
<li><p>地址匿名：MAC、与IP地址匿名化</p>
</li>
<li><p>转图片：取载荷前784（28*28）字节，超则截，短则填</p>
</li>
</ul>
<h2 id="3-3-全局感知模块（Global-aware-representation）"><a href="#3-3-全局感知模块（Global-aware-representation）" class="headerlink" title="3.3 全局感知模块（Global-aware representation）"></a>3.3 全局感知模块（Global-aware representation）</h2><p>&emsp;&emsp;对整个流量输入信息进行聚合,并且引入相对位置机制对字节的位置信息进行建模。</p>
<h3 id="3-3-1-全局信息增强"><a href="#3-3-1-全局信息增强" class="headerlink" title="3.3.1 全局信息增强"></a>3.3.1 全局信息增强</h3><p>&emsp;&emsp;基于CNN的方法由于卷积核的大小关系，无法捕获有效载荷字节之间远程关系，堆叠CNN后，会造成参数多、存在过拟合的问题，这在少样本的情况下尤为明显。</p>
<p>&emsp;&emsp;而注意力机制不会，无视空间距离，考虑每一个载荷之间的相互关系。</p>
<p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242125835.png" alt="img"></p>
<p>对于一个流量图片X，将其拉直，经过运算得到特征向量A：</p>
<p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242135669.png" alt="image-20231124213554439"></p>
<h3 id="3-3-2-相对位置机制"><a href="#3-3-2-相对位置机制" class="headerlink" title="3.3.2 相对位置机制"></a>3.3.2 相对位置机制</h3><p>&emsp;&emsp;但是，上式子中，自注意机制是位置不可知的。此属性丢失了字节的位置信息，导致流量表示不全面。于是改进，加入相对位置，A表示如下：</p>
<p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242137104.png" alt="image-20231124213721617"></p>
<p>P<sup>rel</sup>是相对位置矩阵，比如第i与第j个字节的相对位置可以表示如下：</p>
<script type="math/tex; mode=display">
P^{rel}[i,j]=q_ir_{j-i}</script><p>其中q<sub>i</sub>是字节i 的查询向量，r<sub>j-i</sub>是字节i和字节j之间的相对位置嵌入。</p>
<h3 id="3-3-3-全局增强的特征提取器（Global-enhanced-feature-extractor）"><a href="#3-3-3-全局增强的特征提取器（Global-enhanced-feature-extractor）" class="headerlink" title="3.3.3 全局增强的特征提取器（Global-enhanced feature extractor）"></a>3.3.3 全局增强的特征提取器（Global-enhanced feature extractor）</h3><p>&emsp;&emsp;通过多头注意力机制后，将不同子空间的特征向量进行拼接,得到MA：</p>
<script type="math/tex; mode=display">
MA=Concat[A_1,A_2,···,A_N]W_O</script><p>然后这里还和原始图片X做卷积的结果进行再次拼接，得到输出O:</p>
<script type="math/tex; mode=display">
O=Concat[MA,Conv(X)]</script><blockquote>
<p>自注意力机制+卷积结果拼接作为输出，考虑了载荷之间的距离信息。</p>
</blockquote>
<h2 id="3-4-嵌入生成器"><a href="#3-4-嵌入生成器" class="headerlink" title="3.4 嵌入生成器"></a>3.4 嵌入生成器</h2><p>&emsp;&emsp;这里是四个相同的卷积块进行堆叠，每个都是3*3的卷积核大小，64通道+BN+ReLu+MaxPooling，得到嵌入向量e：</p>
<script type="math/tex; mode=display">
e=f_{\phi}(O)</script><h2 id="3-5-相似度核（Similarity-Kernel）"><a href="#3-5-相似度核（Similarity-Kernel）" class="headerlink" title="3.5 相似度核（Similarity Kernel）"></a>3.5 相似度核（Similarity Kernel）</h2><p>&emsp;&emsp;每一个查询样本x<sup>q</sup>转为嵌入向量e<sup>q</sup>后，与支持集中的每个类型c<sup>i</sup>进行比较，得出相似度进行分类。c<sup>i</sup>是每个i类型的样本嵌入向量评价</p>
<h1 id="4、实验"><a href="#4、实验" class="headerlink" title="4、实验"></a>4、实验</h1><p>这里抛出三个问题：</p>
<ul>
<li><p>小样本学习是否生效</p>
</li>
<li><p>注意力机制与相对位置信息是否必要</p>
</li>
<li><p>GP-Net调参</p>
</li>
</ul>
<p>  数据集：<strong>USTC-TFC2016</strong></p>
<blockquote>
<p>只有一个数据集,个人感觉不够</p>
</blockquote>
<ol>
<li><strong>回答问题1：</strong></li>
</ol>
<p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242126075.png" alt="img"></p>
<p>表里的base是在训练查询集的结果，FewShot是在测试查询集的结果。</p>
<ol>
<li><strong>回答问题2：</strong></li>
</ol>
<p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242126972.png" alt=""></p>
<p>消融实验表明：</p>
<p>第一行表示没有全局感知模块与相对位置机制的模型</p>
<p>第二行表示没有相对位置机制的模型</p>
<blockquote>
<p>但是，我这里感觉在3.3.3 全局感知模块中，加了直接的卷积，没有对那里的卷积进行剔除，感觉这里不好，说不定模型的表现都是基于那个由X直接卷积得到的特征图，而非所谓基于全局感知模块的信息。</p>
</blockquote>
<ol>
<li><strong>回答问题3：</strong></li>
</ol>
<p>调参，不看了</p>
<h1 id="5、总结与思考"><a href="#5、总结与思考" class="headerlink" title="5、总结与思考"></a>5、总结与思考</h1><ul>
<li>亮点：少样本学习、元学习</li>
<li>模型总体结构： 输入为有效载荷，结构为自注意力（加上相对位置信息）+卷积，而且注意力中并行着卷积，没有做这个的消融实验。</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lulu-cloud.github.io/2022/10/15/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB-%E8%AE%BA%E6%96%879%EF%BC%9ADarknetSec_%20A%20novel%20self-attentive%20deep%20learning%20method%20for%20darknet%20traffic...../">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/ava.jpg">
      <meta itemprop="name" content="luluX">
      <meta itemprop="description" content="lulu-cloud的个人GitHub博客">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="lulu-cloud">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/10/15/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB-%E8%AE%BA%E6%96%879%EF%BC%9ADarknetSec_%20A%20novel%20self-attentive%20deep%20learning%20method%20for%20darknet%20traffic...../" class="post-title-link" itemprop="url">加密流量分类-论文9: DarknetSec_ A novel self-attentive deep learning method for darknet traffic</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-10-15 21:27:14" itemprop="dateCreated datePublished" datetime="2022-10-15T21:27:14+08:00">2022-10-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-11-24 21:43:48" itemprop="dateModified" datetime="2023-11-24T21:43:48+08:00">2023-11-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/" itemprop="url" rel="index"><span itemprop="name">科研</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB/" itemprop="url" rel="index"><span itemprop="name">加密流量分类</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="0、摘要"><a href="#0、摘要" class="headerlink" title="0、摘要"></a>0、摘要</h1><p>&emsp;&emsp;提出了一种新的基于自注意力机制深度学习方法DarknetSec，用于暗网流量分类和应用识别；利用一维卷积神经网络(1D CNN)和双向长短期记忆网络(Bi- LSTM)从报文的<strong>有效载荷</strong>内容中捕获局部时空特征，集成自注意机制。此外，DarknetSec从有效载荷统计数据中提取侧通道特征，以增强其分类性能。</p>
<h1 id="1、文章核心观点引入"><a href="#1、文章核心观点引入" class="headerlink" title="1、文章核心观点引入"></a>1、文章核心观点引入</h1><ul>
<li>关于目前基于深度学习的分类方法的缺陷：没有充分考虑从不同数据位置提取的局部特征之间的全局内在依赖关系和隐藏联系，最终导致分类性能不稳定</li>
<li>多头自注意模块的输出和自注意嵌入1D CNN和Bi-LSTM网络提取的局部时空特征同时输入到另一个注意模块中，自动捕获不同注意权重的局部时空特征之间的全局内在依赖关系和隐藏联系</li>
<li><p>用侧通道特征学习模块从有效载荷统计数据中提取特征表示</p>
<h1 id="2、模型结构"><a href="#2、模型结构" class="headerlink" title="2、模型结构"></a>2、模型结构</h1></li>
</ul>
<blockquote>
<p>感觉文章的创新点就是在模型结构了，三个分支网络提取不同的特征，从全局与局部的角度去提取流量特征。</p>
</blockquote>
<h2 id="2-1-模型总览"><a href="#2-1-模型总览" class="headerlink" title="2.1 模型总览"></a>2.1 模型总览</h2><p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242123545.png" alt="在这里插入图片描述"></p>
<h2 id="2-2-预处理层"><a href="#2-2-预处理层" class="headerlink" title="2.2 预处理层"></a>2.2 预处理层</h2><p>&emsp;&emsp;下面解释一下各个输入的预处理步骤，也就是预处理层（最下一层）干的事情。</p>
<ul>
<li><p>预处理pcap或者是pcapng文件，将有两个方向相同的五元组的一组数据包作为流（相当于双向流：会话），<strong>在提取五元组网络流时，我们去掉包头，只保留每个包的应用层数据。</strong></p>
<blockquote>
<ul>
<li>网络层和传输层的协议字段是数据包的基本组成部分，但它们主要是为了网络传输而设计的，而不是为了识别应用程序，故可以剔除</li>
<li>应用层以下的协议字段包含的有效信息很少，不能为细粒度流分类提供充分的区分特征。</li>
</ul>
</blockquote>
</li>
<li><p><strong>Content features:</strong>简言之，提取流前N个packet的前M个字节，长则截断，短则填充0</p>
<p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242123968.png" alt=""></p>
</li>
</ul>
<p>x<sub>content</sub>表示一个样本流的内容特征，所有字节值处于0xff，映射到[0,1]</p>
<ul>
<li><strong>Side-channel features：</strong>由统计（statistical）特征与序列特征（sequential）组成<ul>
<li>选择<strong>流前L个包的长度序列</strong>作为序列特征</li>
<li>统计特征则有很多，如<ol>
<li>流持续时间</li>
<li>数据包之间的时间间隔（最大值、最小值、平均值、标准差、中位数等等）</li>
<li>包长度统计信息（最大值、最小值、平均值、标准差、中位数等等）</li>
<li>接受包统计信息（最大值、最小值、平均值、标准差、中位数等等）</li>
<li>发送包统计信息（最大值、最小值、平均值、标准差、中位数等等）</li>
<li>入包出包数、字节数、每秒出（入）包比</li>
</ol>
</li>
</ul>
</li>
</ul>
<h2 id="2-4-特征提取层"><a href="#2-4-特征提取层" class="headerlink" title="2.4 特征提取层"></a>2.4 特征提取层</h2><ul>
<li><p><strong>Side-channel features</strong>送入MLP进行处理</p>
</li>
<li><p><strong>Content feature</strong>复制成两份，一份送入多头注意力模块提取全局特征，一份送入局部时空特征学习模块，提取局部的时空关联。由1维卷积与Bi-LSTM组成。最后两个模块的输出进行基于注意力内容的融合（从全局角度获取网络流不同数据位置之间的内在依赖关系，有助于综合内容特征的学习），输出O<sub>acff</sub>：</p>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242123186.png" alt="在这里插入图片描述"></p>
<p>  与上面MLP输出的向量进行拼接后送入分类层</p>
<h1 id="4、实验"><a href="#4、实验" class="headerlink" title="4、实验"></a>4、实验</h1><ul>
<li><p>超参数分析：最终敲定N=30，M=256，L=100</p>
</li>
<li><p>消融实验：证明各模块有效</p>
</li>
</ul>
<h1 id="5、总结与思考"><a href="#5、总结与思考" class="headerlink" title="5、总结与思考"></a>5、总结与思考</h1><p>&emsp;&emsp;为什么对侧通道特征提取用MLP，对内容特征提取用attention+CNN+LSTM？可不可以做排列组合，这些部件是否有改进或者说舍弃的必要，使得模型具有轻量性。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lulu-cloud.github.io/2022/10/13/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB-%E8%AE%BA%E6%96%878%EF%BC%9AAn%20Encrypted%20Traffic%20Classification%20Method%20Combining%20Graph%20Convolutional%20Network%20and%20.../">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/ava.jpg">
      <meta itemprop="name" content="luluX">
      <meta itemprop="description" content="lulu-cloud的个人GitHub博客">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="lulu-cloud">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/10/13/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB-%E8%AE%BA%E6%96%878%EF%BC%9AAn%20Encrypted%20Traffic%20Classification%20Method%20Combining%20Graph%20Convolutional%20Network%20and%20.../" class="post-title-link" itemprop="url">加密流量分类-论文8: An Encrypted Traffic Classification Method Combining Graph Convolutional Network and</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-10-13 21:27:14" itemprop="dateCreated datePublished" datetime="2022-10-13T21:27:14+08:00">2022-10-13</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-11-24 21:43:44" itemprop="dateModified" datetime="2023-11-24T21:43:44+08:00">2023-11-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/" itemprop="url" rel="index"><span itemprop="name">科研</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB/" itemprop="url" rel="index"><span itemprop="name">加密流量分类</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="0、摘要"><a href="#0、摘要" class="headerlink" title="0、摘要"></a>0、摘要</h1><p>&emsp;&emsp;构造了一个k -最近邻(KNN)交通图来表示交通数据的结构，从流量结构和流量数据中学习特征表示，利用两层图卷积网络(GCN)架构进行流特征提取和加密流分类。进一步使用自动编码器学习流数据本身的表示，并将其集成到gcn学习的表示中，利用了GCN和自编码器的优点，在只需要少量标记数据的情况下就能获得较高的分类性能。</p>
<h1 id="1、文章核心观点引入"><a href="#1、文章核心观点引入" class="headerlink" title="1、文章核心观点引入"></a>1、文章核心观点引入</h1><ul>
<li><p>样本的结构可以揭示标记样本与未标记样本之间的潜在相似性，为标记样本较少的分类任务提供有价值的指导</p>
</li>
<li><p>在网络流量分析领域中，构建流量图来描述流量结构的方法有很多种，但是这些图主要包含了网络的通信模式和拓扑信息，很少包含流量相似度的信息</p>
</li>
<li><p>构造k -最近邻图来表示交通数据的结构。我们将交通流作为KNN图中的节点。对每个节点，通过相似度计算找到其前K个相似点作为其近邻，并建立边缘连接。进一步利用图卷积网络(GCN)获取交通结构信息，进行流特征提取和分类</p>
</li>
</ul>
<p>​    如图，相当于两个信息分支：</p>
<p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242121899.png" alt="image-20221013174147808"></p>
<blockquote>
<p>关键去找论文如何定义所谓的<strong>相似度</strong></p>
</blockquote>
<h1 id="2、模型方法"><a href="#2、模型方法" class="headerlink" title="2、模型方法"></a>2、模型方法</h1><h2 id="2-1-预处理-Data-Preprocessing"><a href="#2-1-预处理-Data-Preprocessing" class="headerlink" title="2.1 预处理(Data Preprocessing)"></a>2.1 预处理(Data Preprocessing)</h2><ul>
<li><p>流量分割（Traffic Split）:</p>
<p>&emsp;&emsp;去掉pacp文件头的前24个字节，此24字节只包含pacp文件的统计信息，然后基于5元组分成流（flow）的形式，原始流量就转换成流集合F：</p>
<script type="math/tex; mode=display">
F=[f_1,f_2,...,f_{n}]</script><p>对于每一个f<sub>i</sub>,都包含q个包（packet）</p>
<script type="math/tex; mode=display">
f_i=[p_1^i,p_2^i,...,p_{q}^i]</script></li>
<li><p>流量过滤（Traffic Purification）:</p>
<p>&emsp;&emsp;删除每个数据包p中的MAC头，因为它被两个MAC地址填充，也可使它们为零来匿名化这五个元组，并且去掉了所有重复的和空的流文件，避免了对我们分类模型学习能力的不利影响</p>
</li>
<li><p>统一长度（Length Unification）:</p>
<p>&emsp;&emsp;对于大于900字节的流，将其裁剪为900字节，对于小于900字节的流，在流的末尾添加0x00，使其补充为900字节</p>
</li>
<li><p>数据归一化（Data Normalization）:</p>
<p>&emsp;&emsp;将900字节的流序列转换为900维的向量。然后，我们将流向量归一化到范围[0,1]</p>
</li>
</ul>
<p>&emsp;&emsp;经过上述转化，每一个流f<sub>i</sub>都转为流字节向量FBV，原始数据转为矩阵X∈R<sup>N*d</sup>，N代表N个流，d代表一个FBV的维度</p>
<h2 id="2-2-流量图形构建-Traffic-Graph-Construction"><a href="#2-2-流量图形构建-Traffic-Graph-Construction" class="headerlink" title="2.2 流量图形构建(Traffic Graph Construction)"></a>2.2 流量图形构建(Traffic Graph Construction)</h2><p>&emsp;&emsp;对于流数据X，找到对于每个流最相似的k个流，每个流f作为图的一个节点，找到最相似的流作为相邻的节点，在它们之间设置边。对于两个向量x<sub>i</sub>,x<sub>j</sub>,相似度计算公式如下：</p>
<p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242134374.png" alt="image-20231124213451388"></p>
<p>其中指数的分子是表示计算两个向量的欧式距离，在计算相似矩阵S后，选取每个流的top-k相似点作为其近邻，构造无向k最近邻图。这里原文给出了一个依据KNN构造图与原始图（trace graph）的差距，通过相似度计算构建KNN流量图，使得相同应用类型的流量之间建立了更多的连接。KNN图比迹图更容易区分不同类型的流量。</p>
<p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242121406.png" alt="image-20221013200300337"></p>
<h2 id="2-3-分类模型"><a href="#2-3-分类模型" class="headerlink" title="2.3 分类模型"></a>2.3 分类模型</h2><p>&emsp;&emsp;分类模型由GCN与SAE两个部分组成</p>
<ul>
<li><p>GCN：将加密的流量分类转换为节点分类任务，考虑两层GCN架构来获取流量结构信息：</p>
<ul>
<li><p>第一层GCN的输入：邻接矩阵A和流量数据X。A是图的邻接矩阵，X是原始流量数据的矩阵</p>
</li>
<li><p>第一层输出Z<sup>(1)</sup></p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/40b57138b85db831d173302fc1fbfff2.png" alt="image-20221013200951807"></p>
<p>其中：</p>
<script type="math/tex; mode=display">
\widehat{A}=A+I</script></li>
</ul>
</li>
</ul>
<pre><code>D是度数矩阵，D^是对角阵，每个值是A^矩阵的行和，W是权重参数矩阵，外面是激活函数
</code></pre><ul>
<li><p>第二层GCN：</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/e0aa71c57af64ea49c1ce2487e64d23b.png" alt="image-20221013201301290"></p>
<p>损失函数为交叉熵损失。</p>
</li>
</ul>
<ul>
<li><p>SAE：输入为原始流量X，输出为重构的X，最后一层编码器输出为H<sub>e</sub>，损失函数为均方差MSE损失，故模型总损失为两损失之和。</p>
<blockquote>
<p>以上两个部分并没有联结，此处作者的创新将SAE编码器的压缩输出作为辅助信息，与GCN第一层融合，送入GCN第二层，进行分类。由此有如下的Representation Delivery</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242121047.png" alt="image-20221013203608233"></p>
</li>
<li><p><strong>Representation Delivery:</strong>由于KNN流量图是通过相似度计算构造的，因此在KNN图的同一连通分量中，节点的特征更加相似。图卷积运算可能会使它们趋向于收敛于同一值，可能会混合来自不同簇的节点的特征，使它们难以区分，导致过平滑，为了缓解，进行Representation Delivery：</p>
<script type="math/tex; mode=display">
\widetilde{Z}=(1-\phi)Z^{(1)}+\phi H^M_e</script><script type="math/tex; mode=display">
\phi是一个平衡参数</script><p>，故GCN输出改为：</p>
<script type="math/tex; mode=display">
Z^{'}=softmax({\widehat{D}}^{-1/2}\widehat{A}\widehat{D}^{-1/2}{\widehat{Z}}^{(1)}W^{(1)})</script><p>这样可以增强节点的特征表示能力，防止GCN过度强调相邻节点的关联而忽略节点本身的特征，从而提高模型分类性能。</p>
<hr>
</li>
</ul>
<h1 id="4、实验"><a href="#4、实验" class="headerlink" title="4、实验"></a>4、实验</h1><ul>
<li><p>由于是半监督模型，关于标记率的分析</p>
<p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242121660.png" alt="image-20221013203925957"></p>
<p>分析：在所有方法中，随着准确率上升，acc都有增加的趋势，但所提方法的曲线始终高于其他方法，而我们方法的准确率始终优于基线方法。对比结果表明，在低标记率的情况下，将流量结构信息与流量数据相结合进行加密流量分类是有效的。从图中还可以看出，当标记率从10%下降到1%时，我们的方法的准确率下降速度明显慢于其他方法，说明我们的方法具有更好的鲁棒性。</p>
</li>
<li><p>超参数分析：</p>
<p>K与平衡参数\phi</p>
<p>K取3,5,7比较好</p>
<p>\phi取0.5比较好</p>
</li>
<li><p>似乎没有做消融实验，似乎没有较强说服力说明这个<strong>Representation Delivery</strong>是有效的……</p>
</li>
</ul>
<h1 id="5、总结与思考"><a href="#5、总结与思考" class="headerlink" title="5、总结与思考"></a>5、总结与思考</h1><p>&emsp;&emsp;Representation Delivery的创新，感觉这方面没有做相应的消融实验说不过去，毕竟创新点就是这个，不做消融实验怎么说明它一定是有效的捏。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lulu-cloud.github.io/2022/10/06/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB-%E8%AE%BA%E6%96%877%EF%BC%9AMEMG_%20Mobile%20Encrypted%20Traffic%20Classification%20With%20Markov%20Chains%20and%20Graph%20Neural%20Network/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/ava.jpg">
      <meta itemprop="name" content="luluX">
      <meta itemprop="description" content="lulu-cloud的个人GitHub博客">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="lulu-cloud">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/10/06/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB-%E8%AE%BA%E6%96%877%EF%BC%9AMEMG_%20Mobile%20Encrypted%20Traffic%20Classification%20With%20Markov%20Chains%20and%20Graph%20Neural%20Network/" class="post-title-link" itemprop="url">加密流量分类-论文7: MEMG_Mobile Encrypted Traffic Classification With Markov Chains and Graph Neural Network</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-10-06 21:27:14" itemprop="dateCreated datePublished" datetime="2022-10-06T21:27:14+08:00">2022-10-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-11-24 21:43:42" itemprop="dateModified" datetime="2023-11-24T21:43:42+08:00">2023-11-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/" itemprop="url" rel="index"><span itemprop="name">科研</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB/" itemprop="url" rel="index"><span itemprop="name">加密流量分类</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="0、摘要"><a href="#0、摘要" class="headerlink" title="0、摘要"></a>0、摘要</h1><p>&emsp;&emsp;本文提出了一种基于马尔可夫链和图神经网络(MEMG)的移动加密流量分类方法。我们利用马尔可夫链来挖掘流中隐藏的拓扑信息。然后在此基础上构建流图结构，在图的节点特征中加入流量的<strong>序列信息</strong>。我们还设计了一个基于图神经网络的分类器，从图中学习拓扑和顺序特征。分类器可以将图结构映射到嵌入空间中，并通过嵌入向量差对不同的图结构进行分类。</p>
<h1 id="1、概念介绍"><a href="#1、概念介绍" class="headerlink" title="1、概念介绍"></a>1、概念介绍</h1><h2 id="1-1-综述部分"><a href="#1-1-综述部分" class="headerlink" title="1.1 综述部分"></a>1.1 综述部分</h2><h3 id="1-1-1-基于机器学习的加密流量分类"><a href="#1-1-1-基于机器学习的加密流量分类" class="headerlink" title="1.1.1 基于机器学习的加密流量分类"></a>1.1.1 基于机器学习的加密流量分类</h3><ul>
<li><p>依赖于<strong>统计特征</strong>：</p>
<ul>
<li>包级别的统计特征，包括接收和发送包数的平均值、最小值和最大值。</li>
<li><p>TLS的时间分布、未加密的报头信息和流元数据为特征</p>
</li>
<li><p>流的统计特征和突发元数据（burst metadata）中的统计特征</p>
</li>
</ul>
</li>
<li><p>依赖于<strong>流级特征</strong>（Flow-level feature）：一般方法根据流中的每个包提取流的生成概率</p>
<ul>
<li>利用加密流量的消息类型序列，构造生成概率最大的一阶马尔可夫模型对加密流量进行分类</li>
<li>根据证书长度和首包长度，以提高二级马尔可夫模型下的流分类任务的性能</li>
<li>利用包长度马尔可夫随机场(MRF)转换矩阵作为结构特征，构建了加密流量的指纹</li>
</ul>
</li>
</ul>
<h3 id="1-1-2-基于深度学习的加密流量分类"><a href="#1-1-2-基于深度学习的加密流量分类" class="headerlink" title="1.1.2 基于深度学习的加密流量分类"></a>1.1.2 基于深度学习的加密流量分类</h3><ul>
<li><p>DeepPacket借助1-D CNN与堆栈自编码器，通过提取有效载荷对流量进行分类（包级）</p>
</li>
<li><p>有的利用注意力机制对有效载荷进行编码，最后进行分类</p>
<p>&emsp;&emsp;缺点：没有考虑客户端到服务器之间的交互运动等其他流信息，计算开销大</p>
</li>
</ul>
<h2 id="1-2-文章核心观点引入"><a href="#1-2-文章核心观点引入" class="headerlink" title="1.2 文章核心观点引入"></a>1.2 文章核心观点引入</h2><ul>
<li><p>使用一阶马尔可夫链来构造流的拓扑结构，捕获流的隐藏拓扑信息和序列信息，称为马尔可夫图。节点为马尔可夫跃迁状态，边为跃迁概率。</p>
</li>
<li><p>流中每个包的上下文序列添加到图结构中作为节点特征，通过图这种数据结构，将拓扑信息与序列信息结合在一起，将流分类问题转化为图分类问题。</p>
</li>
<li><p>GCN与MLP自动从<strong>拓扑结构信息</strong>和<strong>序列信息</strong>中提取相应特征，并将两种特征进行融合。</p>
<ul>
<li><p>GCN提取拓扑特征</p>
</li>
<li><p>MLP学习序列特征</p>
</li>
</ul>
</li>
</ul>
<h1 id="2、图构造"><a href="#2、图构造" class="headerlink" title="2、图构造"></a>2、图构造</h1><h2 id="2-1-问题定义"><a href="#2-1-问题定义" class="headerlink" title="2.1 问题定义"></a>2.1 问题定义</h2><p>&emsp;&emsp;对于流序列的表示，有许多中序列表示方法表示一个流，如包长序列、消息类型序列等。这里取其中一个，假定N个样本，M个应用，对于数据集中的第i个样本x<sub>i</sub></p>
<script type="math/tex; mode=display">
x_i=[p_1^i,p_2^i,...,p_{li}^i]</script><p>li代表样本x<sub>i</sub>的长度，x<sub>i</sub>的每一个分值x<sub>i</sub><sup>j</sup>代表时间序列为j的值</p>
<blockquote>
<p>这里并没有明说这个值到底是啥，是包长？负载？</p>
</blockquote>
<h2 id="2-2-序列转换"><a href="#2-2-序列转换" class="headerlink" title="2.2 序列转换"></a>2.2 序列转换</h2><p>&emsp;&emsp;考虑一个五元组流的前100个数据包的长度信息，将这个100个数据包作为一个流，转为一个一阶马尔可夫链。假定MTU为1500byte，那么设定10个状态S<sub>j</sub>,j从1-10每个状态的长度区间为150。譬如：1-150长度为状态1；…1351-1500长度为状态10。计算状态转移矩阵W，并将状态转移矩阵W按行归一化，即每一行的元素之和为1.</p>
<p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242119138.png" alt="image-20221006163843150"></p>
<h2 id="2-3-节点与节点状态"><a href="#2-3-节点与节点状态" class="headerlink" title="2.3 节点与节点状态"></a>2.3 节点与节点状态</h2><ul>
<li><p>节点：由于根据数据包长度的大小将原始数据包长度序列转换为<strong>状态序列</strong>，所以<strong>马尔可夫图中的每个节点都包含多个数据包，其长度值属于相应的状态。</strong></p>
</li>
<li><p>节点特征：由于每个节点可能包含多个数据包，故数据包的顺序信息可能会难以提取，故对数据包状态序列进行切片操作：</p>
<ul>
<li><strong>每个数据包的上下文是状态序列的前2个数据包和后2个数据包</strong>，作为该数据包状态的<strong>顺序信息</strong></li>
<li>对于处于相同状态的所有包，使用RNN对那些包的上下文进行压缩，最后形成p维向量，p取128，作为节点特征</li>
</ul>
<h2 id="2-4-马尔科夫图的构造"><a href="#2-4-马尔科夫图的构造" class="headerlink" title="2.4 马尔科夫图的构造"></a>2.4 马尔科夫图的构造</h2></li>
</ul>
<p>&emsp;&emsp;这里给出了前面所有步骤的算法描述:</p>
<ul>
<li>输入：流序列、状态空间、窗口大小</li>
<li>输出：马尔科夫图</li>
</ul>
<p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242119602.png" alt="image-20221006163822285"></p>
<ul>
<li>具体描述：<ul>
<li>1-3行的循环：将原始流序列X<sub>i</sub>转为状态序列B<sub>i</sub>（4），对S取模，这里S=150</li>
<li>5-7行的循环：通过得到的状态序列B<sub>i</sub>构造马尔科夫图的节点集合</li>
<li>8：计算状态转移概率矩阵M</li>
<li>9-15：将M的值作为权重赋给马尔科夫图的边</li>
<li>16：初始化状态特征集合F<sub>i</sub></li>
<li>17-19：对窗口w内的上下文状态序列，进行切片，作为状态序列的顺序信息添加到F<sub>i</sub>中</li>
<li>20-22：对F特征集合的对每一个特征，利用RNN压缩映射到128维向量，作为节点的特征向量</li>
<li>23：得到最终的马尔科夫图G</li>
</ul>
</li>
</ul>
<h2 id="2-5-马尔科夫图MG的优势"><a href="#2-5-马尔科夫图MG的优势" class="headerlink" title="2.5 马尔科夫图MG的优势"></a>2.5 马尔科夫图MG的优势</h2><p>&emsp;&emsp;这里作者任务MG至少包含流量的两种特征：</p>
<ul>
<li><p>马尔科夫链能包含流量的<strong>拓扑信息</strong></p>
</li>
<li><p><strong>包长度序列</strong>也能在拓扑信息中表示</p>
<p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242119411.png" alt="MG的概览"></p>
<h1 id="3、图神经网络结构"><a href="#3、图神经网络结构" class="headerlink" title="3、图神经网络结构"></a>3、图神经网络结构</h1></li>
</ul>
<p>&emsp;&emsp;原始流量转为图结构后，使用GCN与MLP进行特征抽取进行分类。</p>
<p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242120482.png" alt="image-20221006171200053"></p>
<p>&emsp;&emsp;对于图中橙色模块的，分为特征提取与特征池化</p>
<ul>
<li><p>特征提取：</p>
<ul>
<li>提取图的全局拓扑信息：使用GCN，每次使用当前节点的邻接节点进行节点状态更新，得到F<sub>1</sub></li>
<li>提取每一个节点状态的顺序信息：使用MLP，得到F<sub>2</sub></li>
</ul>
</li>
<li><p>特征池化：减少参数，获得更鲁棒的泛化，缓解过拟合</p>
<script type="math/tex; mode=display">
F_{fusion}=Activate(MLP([F_1;F_2]))</script><p>[;]表示拼接，根据对应的分数对节点进行排序，取前k个节点的特征，论文中k取5</p>
</li>
</ul>
<blockquote>
<p>为了考虑到模型结构的全局与局部特征，对每个橙色结构块的输出进行拼接考虑，作为最终分类器的输入（图中的Readout模块）</p>
</blockquote>
<p><img src="https://img-blog.csdnimg.cn/img_convert/b819551006e66d672184de683f7f2ecf.png#pic_center#pic_center" alt="image-20221006172326628"></p>
<ul>
<li>分类器模块：MLP结构，采用交叉熵损失。</li>
</ul>
<h1 id="4、实验"><a href="#4、实验" class="headerlink" title="4、实验"></a>4、实验</h1><ul>
<li><p>与机器学习方法与其他的马尔科夫族方法做了对比</p>
</li>
<li><p>似乎没有做消融实验，不能证明模型每个结构的必要性</p>
</li>
<li><p>实验证明在精度性能的优越性下，MEMG保证的小的内存开销与快速收敛</p>
</li>
<li><p>似乎也没有跟目前的主流的深度学习方法做对比</p>
</li>
</ul>
<h1 id="5、总结与思考"><a href="#5、总结与思考" class="headerlink" title="5、总结与思考"></a>5、总结与思考</h1><p>&emsp;&emsp;马尔科夫图+GNN可以凑一起，并且理由解释得很好，什么拓扑信息、顺序序列信息怎么怎么提取。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lulu-cloud.github.io/2022/10/02/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB-%E8%AE%BA%E6%96%876%EF%BC%9ALearning%20to%20Classify%20A%20Flow-Based%20Relation%20Network%20for%20Encrypted%20Traffic%20Classification/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/ava.jpg">
      <meta itemprop="name" content="luluX">
      <meta itemprop="description" content="lulu-cloud的个人GitHub博客">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="lulu-cloud">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/10/02/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB-%E8%AE%BA%E6%96%876%EF%BC%9ALearning%20to%20Classify%20A%20Flow-Based%20Relation%20Network%20for%20Encrypted%20Traffic%20Classification/" class="post-title-link" itemprop="url">加密流量分类-论文6:Learning to Classify A Flow-Based Relation Network for Encrypted Traffic Classification</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-10-02 21:27:14" itemprop="dateCreated datePublished" datetime="2022-10-02T21:27:14+08:00">2022-10-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-11-24 21:43:39" itemprop="dateModified" datetime="2023-11-24T21:43:39+08:00">2023-11-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/" itemprop="url" rel="index"><span itemprop="name">科研</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB/" itemprop="url" rel="index"><span itemprop="name">加密流量分类</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="0、摘要"><a href="#0、摘要" class="headerlink" title="0、摘要"></a>0、摘要</h1><p>加密流量分类的挑战性问题:</p>
<ul>
<li>网络数据的不平衡性</li>
<li>模型对真实数据的泛化能力</li>
<li>模型对数据大小的过度依赖。</li>
</ul>
<h1 id="1、概念介绍"><a href="#1、概念介绍" class="headerlink" title="1、概念介绍"></a>1、概念介绍</h1><h2 id="1-1-流量加密背景"><a href="#1-1-流量加密背景" class="headerlink" title="1.1 流量加密背景"></a>1.1 流量加密背景</h2><p>&emsp;&emsp;加密技术虽然保护了互联网用户的自由、隐私和匿名性，但也<strong>用户避开了防火墙的检测，绕过了监控系统</strong>。</p>
<p>&emsp;&emsp;由此导致的问题：</p>
<ul>
<li>攻击者通过<strong>加密恶意软件流量</strong>来匿名入侵和攻击系统。</li>
<li>犯罪分子使用隐私增强工具(例如Tor)穿透黑暗网络，在那里他们可以购买毒品、武器和伪造的文件(如护照、驾照、提供合同杀手的媒体)来吸引客户.</li>
</ul>
<h2 id="1-2-流量分类技术的发展（综述部分）"><a href="#1-2-流量分类技术的发展（综述部分）" class="headerlink" title="1.2 流量分类技术的发展（综述部分）"></a>1.2 流量分类技术的发展（综述部分）</h2><ol>
<li>基于端口号</li>
<li>基于有效载荷,也就是DPI方法。<strong>1,2只能针对非加密流量</strong></li>
<li>基于流统计特征的方法，<strong>分类性能取决于人类的特征工程</strong></li>
<li>基于深度学习的方法：<ul>
<li>优点：端到端、具有相当高的学习能力</li>
<li>缺点：<ul>
<li>不能解决数据中类的不均衡问题</li>
<li>训练好的模型不能很好适用于真是流量环境，泛化能力差</li>
<li>过分依赖数据集的大小与数据分布的好坏</li>
</ul>
</li>
</ul>
</li>
</ol>
<h2 id="1-4-文章核心观点引入"><a href="#1-4-文章核心观点引入" class="headerlink" title="1.4 文章核心观点引入"></a>1.4 文章核心观点引入</h2><p>&emsp;&emsp;对于一个新奇概念的样本，人类可以轻易根据对事物共同变化模式的了解，想象该样本在其他环境的样子。如果机器从辨别出在不同环境（<strong>原文这里称作幻觉（hallucination）</strong>）下的同一样本，那么通过一个<strong>致幻器（hallucinator）</strong>产生额外的训练样本，理论上就可以在少量数据样本的情况下学习到不错的泛化能力。</p>
<p>&emsp;&emsp;将从有限的数据中提取先验知识并将其转移到不可见的任务或者环境中，<strong>元学习</strong>是一种解决方案。（不是半监督模型预训练那一套）</p>
<ul>
<li><p>关于<strong>元学习</strong>（学习如何去学习）：</p>
<ol>
<li><p>元级（meta-level）学习器：在不同的训练任务以及对应的训练数据上进行学习，以此作为网络结构的先验知识，下图的F。</p>
</li>
<li><p>基础级（base-level）学习器：为特定任务设计的学习器。由F针对测试任务学习出来的f<br><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242114732.png" alt="在这里插入图片描述"><br><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242114211.png" alt="在这里插入图片描述"></p>
</li>
</ol>
</li>
</ul>
<p>&emsp;&emsp;在元学习阶段，进行多任务学习，称作Training Task，每个任务都有自己的训练集与测试集，也称为支持集（support set）与查询集（query set），学习到一个F。在基础级学习阶段，进行特定任务的学习，称作Testing Task，将Testing task的给入F，得出学习到的f，然后在f上进行传统的训练测试，用f的表现去反映F的泛化能力好坏。</p>
<ul>
<li>分类粒度：基于流的分类（这里是原文：流序列作为唯一的原始流量信息。原始流可以表示为几个具有相同流长度和不同类型的序列(例如，消息类型序列和包长度序列)。一般我们把一种序列看作流序列，其他的序列也可以用同样的方法。）类似于FS-Net的输入，所以此模型输入应该是类似与FS-Net的输入，比如是取<strong>原始流的包长序列</strong>或者<strong>消息类型序列</strong>作为流序列信息，输入到模型</li>
<li><p>分类目标：应用分类</p>
</li>
<li><p>本文的分为训练集、支持集、测试集（支持集和测试集共享相同的标签空间，但训练集有自己的标签空间），原则上只需要支持集与测试集就可以了，但是<strong>支持集中缺乏标记样本，使用训练集上的元学习将提取的知识转移到支持集</strong></p>
</li>
<li><p>训练集合切割成为支持集与查询集？？？</p>
<h1 id="2、模型结构"><a href="#2、模型结构" class="headerlink" title="2、模型结构"></a>2、模型结构</h1><h2 id="2-1总览"><a href="#2-1总览" class="headerlink" title="2.1总览"></a>2.1总览</h2></li>
</ul>
<p>&emsp;&emsp;本文提出基于流的关系网络分类模型（FlowBased Ralation Network，RBRN），从原始流序列学习特征，是端到端的分类模型。</p>
<ul>
<li>致幻器：产生额外样本（相当于一个数据增强器？）</li>
<li>编码器：生成样本特征</li>
<li>解码器：恢复输入序列，也进行特征的学习。编码器解码器都是多层CNN结构</li>
<li><p><strong>基于元学习</strong>的分类器：分类粒度，对应用程序的分类</p>
<h2 id="2-2-集合分割"><a href="#2-2-集合分割" class="headerlink" title="2.2 集合分割"></a>2.2 集合分割</h2><p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242114008.png" alt=""></p>
</li>
</ul>
<p>从训练集中选择跟支持集一样规模的作为集合S：假定支持集n个类，每个类m个样本，从训练集也随机选n个类，每个类选m个样本，剩余的作为查询集。</p>
<h2 id="2-3-致幻器（Hallucinator）"><a href="#2-3-致幻器（Hallucinator）" class="headerlink" title="2.3 致幻器（Hallucinator）"></a>2.3 致幻器（Hallucinator）</h2><p> <img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242114432.png" alt=" "></p>
<ul>
<li><p>Hallucinator的测试流程：</p>
<ol>
<li><p>从原始数据集S中对每一个类别进行采样。</p>
</li>
<li><p>将采用后的样本添加噪声z，送入流产生器Flow（图中红色部分），输出数据增强后的样本Sg</p>
</li>
<li><p>将S<sub>g</sub>与原始数据S合并为S<sub>aug</sub>，并作为最终的训练数据，送入h（分类算法）中进行<strong>预测</strong>。</p>
</li>
</ol>
</li>
<li><p>Hallucinator的训练流程：</p>
<ul>
<li><p>采用元学习的方法来训练Hallucinator与后面的分类器h，要求h对于S<sub>aug</sub>的元素可微，以便进行梯度下降，Hallucinator与后面的网络结构是同步进行训练学习的。</p>
</li>
<li><p>这里目前还没有提及到关于元学习的多任务。</p>
</li>
</ul>
</li>
</ul>
<p> <img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242114179.png" alt="致幻器细节"></p>
<h2 id="2-4-编码器（Encoder）与解码器（Decoder）"><a href="#2-4-编码器（Encoder）与解码器（Decoder）" class="headerlink" title="2.4 编码器（Encoder）与解码器（Decoder）"></a>2.4 编码器（Encoder）与解码器（Decoder）</h2><ul>
<li>编码器输入：S<sub>aug</sub>，输出压缩特征。</li>
<li>体系结构：VGG16网络中的前13个卷积层，舍弃全连接层，理由：以便在最深的编码器输出处保留更高分辨率的特征映射（论文讲的理由）。<ul>
<li>这里说卷积后的特征应该存储起来，但是由于内存限制，采用存储池化层的索引</li>
<li>即池化窗口的最大特征值的位置被存储起来</li>
</ul>
</li>
<li>解码器输入：编码器输出的压缩特征，输出提供给基于元学习的分类器。<ul>
<li>从相应解码器存储的最大池化层索引来进行采样</li>
<li>卷积层的滤波器仍旧是可训练的</li>
</ul>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242117222.png" alt="img"></p>
<h2 id="2-5-基于元学习的分类器"><a href="#2-5-基于元学习的分类器" class="headerlink" title="2.5 基于元学习的分类器"></a>2.5 基于元学习的分类器</h2><p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242117850.png" alt="img"></p>
<ol>
<li>假设样本<strong>x<sub>j</sub></strong>来自查询集<strong>Q</strong>，样本<strong>x<sub>i</sub></strong>来自增强后的数据集**S<sub>aug</sub></li>
<li>通过编码器-解码器输出后为<strong>z<sub>j</sub>=f<sub>encoder-decoder</sub>(x<sub>j</sub>)</strong>为<strong>z<sub>i</sub>=f<sub>encoder-decoder</sub>(x<sub>i</sub>)</strong></li>
<li>定义样本通过特征抽取模块的输出为<strong>m<sub>j</sub>=f<sub>meta-network</sub>(z<sub>j</sub>)</strong>和<strong>m<sub>i</sub></strong>=f<sub>meta-network</sub>(z<sub>i</sub>)**</li>
<li>将<strong>m<sub>j</sub></strong>与<strong>m<sub>i</sub></strong>联结起来，通过关系模型 <strong>J<sub>relation</sub></strong>计算两个样本之间的相关度</li>
<li>采用与最后查询集的实际类形成的独热向量之间的均方差作为损失，构建损失函数</li>
</ol>
<p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242117008.png" alt="img"></p>
<h1 id="4、实验"><a href="#4、实验" class="headerlink" title="4、实验"></a>4、实验</h1><ul>
<li><p>在小样本学习有不错的表现：在Full ISCX vpn -非vpn流量数据集中，为每个应用程序选择1000条流量记录作为训练集，其他的作为测试集，仍旧有不错的效果。</p>
</li>
<li><p>在数据不均衡样本集有不错的表现</p>
</li>
<li><p>在复杂环境时能保证不错的泛化能力：<strong>在均衡样本集中训练，在非均衡上测试，对比其他模型，表现出不错的效果</strong></p>
<blockquote>
<p>不太理解在均匀数据集上训练的模型在非均衡数据集上进行测试，如何能体现出泛化能力。</p>
</blockquote>
</li>
</ul>
<h1 id="5、总结与思考"><a href="#5、总结与思考" class="headerlink" title="5、总结与思考"></a>5、总结与思考</h1><ul>
<li>从李宏毅老师学习到元学习的有关概念，感觉这里元学习作者没有太突出出来，我的理解是训练集很大，每次选一个子集合作为支持集，就相当于一个元学习任务了，这样多次选训练集子集，相当于对元分类器进行多任务训练。……不知道理解对不对。。。</li>
<li>网络模型挺深，模块多，实验部分做了消融实验以此证明每部分都是有必要的。</li>
<li>不太理解在编码器解码器中对于池化索引的记录的点，以及解码器的存在的意义，只需编码部分可不可以?</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lulu-cloud.github.io/2022/09/27/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB-%E8%AE%BA%E6%96%875%EF%BC%9AMATEC_A_lightweight_neural_network_for_online_encrypted_traffic/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/ava.jpg">
      <meta itemprop="name" content="luluX">
      <meta itemprop="description" content="lulu-cloud的个人GitHub博客">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="lulu-cloud">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/09/27/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB-%E8%AE%BA%E6%96%875%EF%BC%9AMATEC_A_lightweight_neural_network_for_online_encrypted_traffic/" class="post-title-link" itemprop="url">加密流量分类-论文5:MATEC_A_lightweight_neural_network_for_online_encrypted_traffic</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-09-27 21:27:14" itemprop="dateCreated datePublished" datetime="2022-09-27T21:27:14+08:00">2022-09-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-11-24 21:43:36" itemprop="dateModified" datetime="2023-11-24T21:43:36+08:00">2023-11-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/" itemprop="url" rel="index"><span itemprop="name">科研</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB/" itemprop="url" rel="index"><span itemprop="name">加密流量分类</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="0、摘要"><a href="#0、摘要" class="headerlink" title="0、摘要"></a>0、摘要</h1><p> &emsp;&emsp;现有的深度学习方法为了获得高精度的分类结果而牺牲了效率，已经不适合大量加密流量的场景，本文提出了一种实现为MATEC的轻量级<strong>在线</strong>方法，<strong>遵循“精简模块重用最大化”的设计原则（Maximizing the reuse of thin modules）</strong>。</p>
<h1 id="1、问题引入"><a href="#1、问题引入" class="headerlink" title="1、问题引入"></a>1、问题引入</h1><p> &emsp;&emsp;老规矩，先说其他方案的缺点：</p>
<ul>
<li><p>统计特征+基于机器学习的方法：要获得流量的统计特征，需要观察流的全部或者大部分，内存开销大，只能适用于离线分类。</p>
</li>
<li><p>基于深度学习的方法：为了追求精度，目前提出的神经网络运行时空开销大，效率不够高。</p>
<blockquote>
<p> 所以本文提出了MATEC的轻量级的神经网络，可以用于在线流分类，输入是<strong>流中的随机位置的三个数据包</strong>；基本结构：<strong>多头注意力机制+一维CNN</strong>；期望能提取全局（流级）与局部（包级）的特征，<strong>全局特征来自流中信息包之间的交互，而局部特征则包含在一些原始信息包的字节中。</strong></p>
<p>此外，这篇文章的方法通过迁移学习，也对零日应用的流量探测有一定效用。</p>
</blockquote>
</li>
</ul>
<h1 id="2、流分类的相关工作（综述部分）"><a href="#2、流分类的相关工作（综述部分）" class="headerlink" title="2、流分类的相关工作（综述部分）"></a>2、流分类的相关工作（综述部分）</h1><h2 id="2-1-加密流量分类"><a href="#2-1-加密流量分类" class="headerlink" title="2.1 加密流量分类"></a>2.1 加密流量分类</h2><p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242112540.png" alt="分类流程"></p>
<p>&emsp;分类目标：</p>
<ul>
<li><p>基于协议(如HTTP、SSL、SMTP、DNS或QUIC)</p>
</li>
<li><p>基于流量类型(如视频、聊天或浏览)</p>
</li>
<li><p>基于应用程序(如Amazon、Apple、Microsoft或谷歌)</p>
</li>
<li><p>基于网站</p>
</li>
</ul>
<p>&emsp;  分类方法是否在线，可以分为：</p>
<ul>
<li><p>在线流量分类（本文提出的是在线方法）</p>
</li>
<li><p>离线流量分类</p>
</li>
</ul>
<p>常见流量分类方法，包级（Packet-Based）与流级(Flow-Based),然后介绍了什么是包、什么是流。</p>
<blockquote>
<p>流是指所有具有五元组(即传输层协议、源IP、源端口、目的IP、目的端口)相同值的报文，源和目的可以交换。有的论文觉得不能交换，能交换的称作为<strong>会话（session）</strong></p>
</blockquote>
<ul>
<li><p>基于包级（报文级）的分类方法：直接将数据包的字节作为输入，包括报头信息与有效载荷。<strong>基于包的方法只关注少数包的详细信息，缺乏对全局特征的关注。</strong>（Deep Packet）</p>
</li>
<li><p>基于流级的分类方法：流级特征包括了全局信息。</p>
<ul>
<li>基于机器学习的方法：需要手动设计并且提取统计特征，大部分必须观察整个流或流中的大部分数据包才能获得这些特征，更适合于离线分类。</li>
<li>基于深度学习的方法：有使用Bi-GRU对流的字节序列或者流中的包长序列进行特征提取用于分类（FS-Net），有将流中连续的几个报文作为1D-CNN的输入进行分类，有同时使用CNN与RNN分别提取流量的空间特征与时间特征。<strong>但是RNN中单元之间的依赖关系使得等待上一个单元的输出非常耗时，本文提出的多头注意力（Multi-head attention）方法就没有这种劣势。</strong></li>
</ul>
</li>
</ul>
<blockquote>
<p> 这篇文章的综述特别详尽</p>
</blockquote>
<h1 id="3、模型结构"><a href="#3、模型结构" class="headerlink" title="3、模型结构"></a>3、模型结构</h1><h2 id="3-1嵌入层（Embedding）"><a href="#3-1嵌入层（Embedding）" class="headerlink" title="3.1嵌入层（Embedding）"></a>3.1嵌入层（Embedding）</h2><ul>
<li><p>输入：数据流中的随机位置的连续三个包，既利用了包的统计特征（如包的长度、相对位置）也利用了包的字节特征，对于一个包xi，它的浅层特征向量如下：</p>
<script type="math/tex; mode=display">
x_i=\{x_{i_1},x_{i_2},..,x_{i_M}\}</script><p>每一个分量代表包的一个特征，例如第一个分量可以代表包的相对位置、第二个分量可以代表包长、第三个分量可以代表删除以太网头后的第一个784字节……</p>
</li>
<li><p>嵌入：对于xi中的每一个分量，若其是向量特征，做如下变换，</p>
<script type="math/tex; mode=display">
e_{i_j}=U_jx_{i_j}</script><p>这样将改向量映射到j维向量，若其是标量特征，则做如下变换</p>
<script type="math/tex; mode=display">
e_{i_j}=u_jx_{i_j}</script><p>这样，不论是向量特征还是标量特征都会被映射到相同的表示，转换后的向量ei如下：</p>
<script type="math/tex; mode=display">
e_i=W_{map}[e_{i_1},e_{i_2},..,e_{i_n}]</script><script type="math/tex; mode=display">
W_{map}∈R^{d*m}</script><p>因此，一个包就转为一个d维向量，一个流转为N*d维矩阵，这里研究N取3,即随机选取流中3个连续数据包的那个3。嵌入向量的位置编码采用绝对编码方式。</p>
</li>
</ul>
<h2 id="3-2-注意力编码层"><a href="#3-2-注意力编码层" class="headerlink" title="3.2 注意力编码层"></a>3.2 注意力编码层</h2><p> &emsp;&emsp;这里期望注意力编码层能够捕获数据的高维特征，并且捕获到数据包之间的交互关系。这里的注意力层跟Transformer块很像，给出图</p>
<p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242112113.png" alt="多头注意力编码器"></p>
<p>使用注意力机制的好处：</p>
<ul>
<li>并行学习，运算快，参数量少</li>
<li><p>将数据映射到多个高维度，更能发掘潜在信息</p>
<h2 id="3-3-全连接层"><a href="#3-3-全连接层" class="headerlink" title="3.3 全连接层"></a>3.3 全连接层</h2><ul>
<li><p>将编码后的特征作为输入，输出为预测标签的概率分布</p>
</li>
<li><p><strong>结构可变，针对不同任务灵活改变全连接层的输出神经元个数，输入的个数是固定的，</strong>利用迁移学习优化对新交通数据的<strong>微调</strong>训练，可以加快模型的收敛速度。</p>
</li>
</ul>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242112169.png" alt="模型结构"></p>
<h1 id="4、总结与思考"><a href="#4、总结与思考" class="headerlink" title="4、总结与思考"></a>4、总结与思考</h1><ul>
<li>模型结构声称是第一个将注意力机制引入流量分类任务。</li>
<li>通过调整网络结构后端的FC层，可以在新任务上通过少量标签样本进行微调，迅速收敛达到不错的效果。</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lulu-cloud.github.io/2022/09/20/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BBtorch%E5%AE%9E%E8%B7%B51%EF%BC%9A1D-CNN%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E4%B8%8E%E6%B5%8B%E8%AF%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/ava.jpg">
      <meta itemprop="name" content="luluX">
      <meta itemprop="description" content="lulu-cloud的个人GitHub博客">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="lulu-cloud">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/09/20/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BBtorch%E5%AE%9E%E8%B7%B51%EF%BC%9A1D-CNN%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E4%B8%8E%E6%B5%8B%E8%AF%95/" class="post-title-link" itemprop="url">加密流量分类-实践1: 1D-CNN模型训练与测试</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-09-20 21:27:14" itemprop="dateCreated datePublished" datetime="2022-09-20T21:27:14+08:00">2022-09-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-11-24 21:44:00" itemprop="dateModified" datetime="2023-11-24T21:44:00+08:00">2023-11-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/" itemprop="url" rel="index"><span itemprop="name">科研</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB/" itemprop="url" rel="index"><span itemprop="name">加密流量分类</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>模型：model.py<br>论文参数：<br><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242110890.png" alt="论文参数"></p>
<pre><code class="lang-python">import torch.nn as nn
import torch
import torch.nn.functional as F

class OneCNNC(nn.Module):
    def __init__(self,label_num):
        super(OneCNNC,self).__init__()
        self.layer_1 = nn.Sequential(
            # 输入784*1
            nn.Conv2d(1,32,(1,25),1,padding=&#39;same&#39;),
            nn.ReLU(),
            # 输出262*32
            nn.MaxPool2d((1, 3), 3, padding=(0,1)),
        )
        self.layer_2 = nn.Sequential(
            # 输入262*32
            nn.Conv2d(32,64,(1,25),1,padding=&#39;same&#39;),
            nn.ReLU(),
            # 输入262*64
            nn.MaxPool2d((1, 3), 3, padding=(0,1))
        )
        self.fc1=nn.Sequential(
            # 输入88*64
            nn.Flatten(),
            nn.Linear(88*64,1024),
            # 自主加了两个dropout层
            nn.Dropout(p=0.5),
            nn.Linear(1024,label_num),
            nn.Dropout(p=0.3)
        )
    def forward(self,x):
        # print(&quot;x.shape:&quot;,x.shape)
        x=self.layer_1(x)
        # print(&quot;x.shape:&quot;,x.shape)
        x=self.layer_2(x)
        # print(&quot;x.shape:&quot;,x.shape)
        x=self.fc1(x)
        # print(&quot;x.shape:&quot;,x.shape)
        return x



# x=torch.tensor([[1, 1,  0,  1,  2,  3],
#                 [1, 1,  4,  5,  6,  7],
#                 [1, 10, 8,  9, 10, 11]],dtype=torch.float32)
# x=x.reshape(1,3,-1)


# out_tensor=F.max_pool2d(x,(3,1),stride=3,padding=0)

# print(out_tensor)
</code></pre>
<p>数据部分：<br><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242110021.png" alt="在这里插入图片描述"><br><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242110530.png" alt="在这里插入图片描述"><br>数据读取：data.py</p>
<pre><code>import os
from torch.utils.data import Dataset
import gzip
import numpy as np
class DealDataset(Dataset):
    &quot;&quot;&quot;
        读取数据、初始化数据
    &quot;&quot;&quot;

    def __init__(self, folder, data_name, label_name, transform=None):
        (train_set, train_labels) = load_data(folder, data_name,label_name)  
        self.train_set = train_set
        self.train_labels = train_labels
        self.transform = transform

    def __getitem__(self, index):
        img, target = self.train_set[index], int(self.train_labels[index])
        # 这里要copy一下不然会报错
        img=img.copy()
        # 28*28 -&gt; 764
        img=img.reshape(1,1,-1)
        # target=target.copy()
        if self.transform is not None:
            img = self.transform(img)
        return img, target

    def __len__(self):
        return len(self.train_set)


def load_data(data_folder, data_name, label_name):
    with gzip.open(os.path.join(data_folder, label_name), &#39;rb&#39;) as lbpath:  
        y_train = np.frombuffer(lbpath.read(), np.uint8, offset=8)

    with gzip.open(os.path.join(data_folder, data_name), &#39;rb&#39;) as imgpath:
        x_train = np.frombuffer(
            imgpath.read(), np.uint8, offset=16).reshape(len(y_train), 28, 28)
    return (x_train, y_train)
</code></pre><p>模型训练主模块：</p>
<pre><code>from random import shuffle
import time
import sys
import torch.nn as nn
import numpy as np
import os

import torchvision

from model import OneCNN,CNNImage,OneCNNC
from torchvision import datasets,transforms
import gzip
import torch
from data import DealDataset


def main():
    # Device configuration
    device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;)

    # 设置超参数
    batch_size = 50
    lr = 1.0e-4
    num_epochs = 40
    label_num = 12



    # 导入数据
    folder_path_list=[
        r&quot;2.encrypted_traffic_classification/3.PerprocessResults/12class/FlowAllLayers&quot;,
        r&quot;2.encrypted_traffic_classification/3.PerprocessResults/12class/FlowL7&quot;,
        r&quot;2.encrypted_traffic_classification/3.PerprocessResults/12class/SessionAllLayers&quot;,
        r&quot;2.encrypted_traffic_classification/3.PerprocessResults/12class/SessionL7&quot;
                      ]

    # 选择哪个数据集
    task_index = 0

    folder_path = folder_path_list[task_index]
    train_data_path = &quot;train-images-idx3-ubyte.gz&quot;
    train_label_path = &quot;train-labels-idx1-ubyte.gz&quot;
    test_data_path = &quot;t10k-images-idx3-ubyte.gz&quot;
    test_label_path = &quot;t10k-labels-idx1-ubyte.gz&quot;
    trainDataset = DealDataset(folder_path,train_data_path,train_label_path)
    testDataset = DealDataset(folder_path,test_data_path,test_label_path

    train_loader = torch.utils.data.DataLoader(
        dataset=trainDataset,
        batch_size=batch_size,
        shuffle=True
    )

    test_loader = torch.utils.data.DataLoader(
        dataset=testDataset,
        batch_size=batch_size,
        shuffle=False
    )


    # 定义模型
    model = OneCNNC(label_num)
    model = model.to(device)
    # model = CNNImage()

    # Loss and optimizer
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.SGD(model.parameters(), lr=lr)

    # Train the model
    total_step = len(train_loader)
    for epoch in range(num_epochs):
        for i, (images, labels) in enumerate(train_loader):
            # images=images.reshape(-1,1,28,28)
            images = images.to(device)
            labels = labels.to(device)

            # Forward pass
            outputs = model(images.to(torch.float32))
            loss = criterion(outputs, labels)

            # Backward and optimize
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            if (i+1) % 100 == 0:
                print (&#39;Epoch [&#123;&#125;/&#123;&#125;], Step [&#123;&#125;/&#123;&#125;], Loss: &#123;:.4f&#125;&#39; 
                    .format(epoch+1, num_epochs, i+1, total_step, loss.item()))
    # Test the model
    model.eval()
    with torch.no_grad():
        correct = 0
        total = 0
        test_length = len(testDataset)
        for images, labels in test_loader:
            images = images.to(device)
            labels = labels.to(device)
            outputs = model(images.to(torch.float32))
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

        print(&#39;Test Accuracy of the model on the &#123;&#125; test images: &#123;&#125; %&#39;.format(test_length,100 * correct / total)) 

    # Save the model checkpoint
    torch.save(model.state_dict(), &#39;model.ckpt&#39;)

if __name__ == &#39;__main__&#39;:
    main()
</code></pre><p>运行结果：<br><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242109685.jpeg" alt="实验结果"></p>
<p>项目地址：<a target="_blank" rel="noopener" href="https://github.com/lulu-cloud/Pytorch-Encrypted-Traffic-Classification-with-1D_CNN">https://github.com/lulu-cloud/Pytorch-Encrypted-Traffic-Classification-with-1D_CNN</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lulu-cloud.github.io/2022/09/18/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB-%E8%AE%BA%E6%96%874%EF%BC%9AEndtoend%20Encrypted%20Traffic%20Classification%20with%20One-dimensional%20Convolution%20Neural%20Networks/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/ava.jpg">
      <meta itemprop="name" content="luluX">
      <meta itemprop="description" content="lulu-cloud的个人GitHub博客">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="lulu-cloud">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/09/18/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB-%E8%AE%BA%E6%96%874%EF%BC%9AEndtoend%20Encrypted%20Traffic%20Classification%20with%20One-dimensional%20Convolution%20Neural%20Networks/" class="post-title-link" itemprop="url">加密流量分类-论文4: Endtoend Encrypted Traffic Classification with One-dimensional Convolution Neural Networks</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-09-18 21:27:14" itemprop="dateCreated datePublished" datetime="2022-09-18T21:27:14+08:00">2022-09-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-11-24 21:43:34" itemprop="dateModified" datetime="2023-11-24T21:43:34+08:00">2023-11-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/" itemprop="url" rel="index"><span itemprop="name">科研</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB/" itemprop="url" rel="index"><span itemprop="name">加密流量分类</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="0、摘要"><a href="#0、摘要" class="headerlink" title="0、摘要"></a>0、摘要</h1><p>&emsp;&emsp;此篇方法是第一个将端到端的方法应用到加密流量分类领域，使用数据集ISCX-VPN-NonVPN-2016数据集进行研究。</p>
<h1 id="1、概念介绍"><a href="#1、概念介绍" class="headerlink" title="1、概念介绍"></a>1、概念介绍</h1><h2 id="1-1-流量加密技术"><a href="#1-1-流量加密技术" class="headerlink" title="1.1 流量加密技术"></a>1.1 流量加密技术</h2><p>&emsp;&emsp;依据ISO/OSI层的不同，加密技术可以分为</p>
<ul>
<li><p>应用层加密：应用程序在应用层实现自己的协议以实现数据的安全传输(如BitTorrent或Skype)，在一些论文中也称为常规加密。</p>
</li>
<li><p>表示层加密</p>
</li>
<li><p>网络层加密：如IPSec加密协议</p>
</li>
</ul>
<h2 id="1-2-常见加密协议"><a href="#1-2-常见加密协议" class="headerlink" title="1.2 常见加密协议"></a>1.2 常见加密协议</h2><ul>
<li>IPSec协议：网络层加密协议。分为<strong>传输</strong>与<strong>隧道</strong>两种模式<ul>
<li>传输模式：在IP报头和高层协议报头中插入一个IPSec报头，该模式不会改变IP报头中的目的地址，源IP地址也保持明文状态。</li>
<li>隧道模式：报文的源IP地址以及数据被封装成一个新的IP报文，并在内部和外部报头之间插入一个IPSec报头，原来的IP地址作为需要进行安全业务处理的一部分来提供安全保护，并且该模式下，可以对整个IP报文进行加密操作，常用来实现<strong>虚拟专用网VPN</strong>。</li>
</ul>
</li>
<li>SSL/TLS协议：传输层协议。对于TLS，简单地说，是在TCP层之上再封装了SSL层。安全套接层协议 SSL 提供应用层和传输层之间的数据安全性机制，在客户端和 服务器之间建立安全通道，对数据进行加密和隐藏，确保数据在传输过程中不被改变。 SSL 协议在应用层协议通信之前就已经完成加密算法和密钥的协商，在此之后所传送的 数据都会被加密，从而保证通信的私密性。</li>
<li>HTTPS协议：应用层加密协议。HTTPS中，通信协议使用安全传输层TLS或者SSL进行加密。</li>
<li>QUIC协议：应用层加密协议。全称（Quick UDP Internet Connection），是谷歌制定的一种基于UDP的低时延的互联网传输层协议。QUIC融合了包括TCP、TLS、HTTP/2.0等协议的特性，但是基于<strong>UDP</strong>传输，主要目标就是<strong>减少连接延迟</strong>，避免HTTP/2.0的线头阻塞（Head-of-Line Blocking）问题。</li>
</ul>
<h2 id="1-3-端到端的流量分类方法与传统方法的对比"><a href="#1-3-端到端的流量分类方法与传统方法的对比" class="headerlink" title="1.3 端到端的流量分类方法与传统方法的对比"></a>1.3 端到端的流量分类方法与传统方法的对比</h2><p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242102745.png" alt="方法对比"></p>
<ul>
<li>传统的分类方法流程：从原始流量中，经过人类专家精心设计的特征工程模块进行特征提取，形成基于流级（flow）或者包级（packet）的特征，最后送入分类器进行分类（一般是传统的基于机器学习的分类模型，如LR、SVM、C4.5等分类器）</li>
<li>端到端的分类方法流程：从原始流量直接进入模型，映射到它对应的label。</li>
</ul>
<h2 id="1-4-网络流量划分粒度"><a href="#1-4-网络流量划分粒度" class="headerlink" title="1.4 网络流量划分粒度"></a>1.4 网络流量划分粒度</h2><p>&emsp;&emsp;不同的拆分粒度会导致不同的流量单位。主流的研究分为包级（packet）、流级（flow）、会话级（session）</p>
<ul>
<li><p>原始流量（raw traffic）可以定义为|P|个包的集合</p>
<script type="math/tex; mode=display">
P=\{p^1,...p^{|P|}\}</script><p>其中，</p>
<script type="math/tex; mode=display">
p^i=(x^i,b^i,t^i),i=1,2,...,|P|</script><ul>
<li>第一个分量xi 表示五元组(源IP、源端口、目的IP、目的端口和传输级协议)</li>
<li>第二个分量bi表示包的长度，单位是字节（byte）</li>
<li>第三个分量ti表示当前包开始传输的时间</li>
</ul>
</li>
<li><p>流级：一组原始流量P可以划分为多个子集，子集中的所有数据包按照时间排列，每一个子集就称为一个流（flow）</p>
<script type="math/tex; mode=display">
f=(x,b,d,t)=\{p^1=(x^1,b^1,t^1),p^2=(x^2,b^2,t^2),...,p^n=(x^n,b^n,t^n)\},  t^1<...<t^n</script><ul>
<li>x表示流中所有包的五元组（都是相同的）</li>
<li>b表示流中所有包的字节总和</li>
<li>d表示流持续时间，可以表示为d=tn-t1</li>
<li>t则是流中第一个数据包开始发送的时间</li>
</ul>
</li>
<li>会话级：一个会话可以定义为双向流，即流的五元组中的源IP/源port与目的IP/目的port可以互换(session)</li>
</ul>
<h1 id="2、ISCX-VPN-NonVPN-2016数据集"><a href="#2、ISCX-VPN-NonVPN-2016数据集" class="headerlink" title="2、ISCX-VPN-NonVPN-2016数据集"></a>2、ISCX-VPN-NonVPN-2016数据集</h1><ul>
<li><p>ISCX-VPN-NonVPN-2016包括7种常规加密流量和7种协议封装流量</p>
<p>数据集结构如下：</p>
<p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242102172.png" alt="ISCX数据集概览"></p>
</li>
</ul>
<ul>
<li><p>ISCX数据集的流特征有14类标签，但原始流量没有标签，因此我们根据数据集中pcap文件的论文描述对其进行标签。而一些文件，如Facebook_video.pcap可以被标记为“浏览器”或“流媒体”，所有与“浏览器”和“vpn -浏览器”相关的文件都有这个问题。决定不给这些文件贴上标签。</p>
<p>最后，标记的ISCX数据集有12类，包括6类常规加密流量和6类协议封装流量。</p>
<h1 id="3、模型结构"><a href="#3、模型结构" class="headerlink" title="3、模型结构"></a>3、模型结构</h1><h2 id="3-1总览"><a href="#3-1总览" class="headerlink" title="3.1总览"></a>3.1总览</h2></li>
</ul>
<p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242102715.png" alt="模型概览"></p>
<h2 id="3-2-数据预处理"><a href="#3-2-数据预处理" class="headerlink" title="3.2 数据预处理"></a>3.2 数据预处理</h2><p> &emsp;&emsp;使用论文团队开发的工具USTC-TL2016进行数据预处理</p>
<ul>
<li><p>流量分割：这个步骤将一个连续的原始流量分割为多个离散的流量单元。输入数据格式为pcap。如果表示类型为Flow + All或Session + All，则输出数据格式为pcap。当表示类型为Flow + L7或Session + L7时，输出数据格式为bin。即.pacp 转化为.pacp或者.bin。</p>
<ul>
<li><p>ALL表示使用了所有层的包层选择</p>
</li>
<li><p>L7表示仅仅使用了OSI模型的第七层（应用层）的包层选择</p>
</li>
</ul>
</li>
<li>流量清理：对数据链路层和IP层的MAC地址和IP地址分别进行随机化。</li>
<li>图像生成（非必要）：将所有文件修剪为统一的长度。如果文件大小大于784字节，则裁剪为784字节。如果文件大小小于784字节，则在最后添加0x00以补充到784字节。然后，具有相同大小的结果文件被转换为灰色图像。原始文件的每个字节代表一个像素，例如0x00是黑色的，0xff是白色的。这种转换是可选的，可以简单地直接将文件转换为IDX文件。</li>
<li><p>IDX转换：此步骤将图像转换为IDX格式文件，IDX文件包含一组图像的所有像素和统计信息。IDX格式是机器学习领域中常用的文件格式。</p>
<h2 id="3-3-训练阶段"><a href="#3-3-训练阶段" class="headerlink" title="3.3 训练阶段"></a>3.3 训练阶段</h2><p>&emsp;&emsp;采用小批量随机梯度下降(SGD)。采用10倍交叉验证技术，保证了CNN模型的泛化能力。</p>
<h2 id="3-4-测试阶段"><a href="#3-4-测试阶段" class="headerlink" title="3.4 测试阶段"></a>3.4 测试阶段</h2><p>&emsp;&emsp;利用训练好的CNN模型进行测试</p>
<h2 id="3-5-1D-CNN模型"><a href="#3-5-1D-CNN模型" class="headerlink" title="3.5 1D-CNN模型"></a>3.5 1D-CNN模型</h2></li>
<li><p>输入：取流或者会话的前n个字节作为模型输入，n取784（28*28）</p>
</li>
<li><p>使用1D-CNN的理由：CNN主要应用于计算机视觉领域，如图像分类。CNN适用于以下类型的数据:</p>
<ul>
<li><p>多数组形式的数据;</p>
</li>
<li><p>具有强局部相关性的数据;</p>
</li>
<li><p>特征可以出现在任何地方的数据;</p>
</li>
<li><p>对象不受平移和扭曲影响的数据。</p>
</li>
</ul>
</li>
</ul>
<p>具体来说，1D-CNN适合于诸如顺序数据或语言之类的数据。2D-CNN适用于图像或音频声谱图等数据。3D-CNN适用于视频或体积图像等数据。网络流量本质上是顺序数据。它是一种按层次结构组织的一维字节流。字节、分组、会话和整个流量的结构与自然语言处理领域中的字符、单词、句子和整篇文章的结构非常相似。近年来，CNN在NLP中的成功应用均采用1D-CNN，如情感分析、文本分类。本文在这些研究的启发下，使用一维cnn执行加密流量分类任务，并将其性能与二维cnn进行比较。</p>
<h1 id="4、实验"><a href="#4、实验" class="headerlink" title="4、实验"></a>4、实验</h1><ul>
<li><p><strong>模型参数</strong>：</p>
<p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242102167.png" alt="模型参数"></p>
</li>
</ul>
<ul>
<li><p><strong>超参数设置</strong>：</p>
<p>epoch：40</p>
<p>learn_rating: 1.0e-4</p>
<p>batch_size: 50</p>
</li>
<li><p><strong>实验结果</strong>：<br><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242103515.png" alt="论文实验结果"></p>
<blockquote>
<p>论文给出的源码是基于tensorflow实现的，这里用torch写了一个CNN做了一下exp4，也就是上图的红色箭头的结果。如下,基本差不多<br><img src="https://img-blog.csdnimg.cn/f2a88816192042128862e4a3d3dc2e61.jpeg#pic_center" alt="torch复现"></p>
</blockquote>
</li>
</ul>
<pre><code>class OneCNNC(nn.Module):
    def __init__(self,label_num):
        super(OneCNNC,self).__init__()
        self.layer_1 = nn.Sequential(
            # 输入784*1
            nn.Conv2d(1,32,(1,25),1,padding=&#39;same&#39;),
            nn.ReLU(),
            # 输出262*32
            nn.MaxPool2d((1, 3), 3, padding=(0,1)),
        )
        self.layer_2 = nn.Sequential(
            # 输入262*32
            nn.Conv2d(32,64,(1,25),1,padding=&#39;same&#39;),
            nn.ReLU(),
            # 输入262*64
            nn.MaxPool2d((1, 3), 3, padding=(0,1))
        )
        self.fc1=nn.Sequential(
            # 输入88*64
            nn.Flatten(),
            nn.Linear(88*64,1024),
            # 这里自己加了两个dropout层
            nn.Dropout(p=0.5),
            nn.Linear(1024,label_num),
            nn.Dropout(p=0.3)
        )
    def forward(self,x):
        # print(&quot;x.shape:&quot;,x.shape)
        x=self.layer_1(x)
        # print(&quot;x.shape:&quot;,x.shape)
        x=self.layer_2(x)
        # print(&quot;x.shape:&quot;,x.shape)
        x=self.fc1(x)
        # print(&quot;x.shape:&quot;,x.shape)
        return x
</code></pre><ul>
<li><strong>对比分析</strong>：<ol>
<li><strong>与2D-CNN的对比</strong></li>
<li><strong>与C4.5分类器的对比</strong><h1 id="5、总结与思考"><a href="#5、总结与思考" class="headerlink" title="5、总结与思考"></a>5、总结与思考</h1></li>
</ol>
</li>
<li>学习一下流量数据的预处理套路</li>
<li>第一个端到端的基于神经网络的分类模型？1D-CNN结果简单，分类效果好，基于深度学习的方法在流量分类中有巨大潜力。</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lulu-cloud.github.io/2022/09/04/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB-%E8%AE%BA%E6%96%873%EF%BC%9AFS-Net_%20A%20Flow%20Sequence%20Network%20For%20Encrypted%20Traffic%20Classification/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/ava.jpg">
      <meta itemprop="name" content="luluX">
      <meta itemprop="description" content="lulu-cloud的个人GitHub博客">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="lulu-cloud">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/09/04/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB-%E8%AE%BA%E6%96%873%EF%BC%9AFS-Net_%20A%20Flow%20Sequence%20Network%20For%20Encrypted%20Traffic%20Classification/" class="post-title-link" itemprop="url">加密流量分类-论文3: FS-Net_ A Flow Sequence Network For Encrypted Traffic Classification</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-09-04 21:27:14" itemprop="dateCreated datePublished" datetime="2022-09-04T21:27:14+08:00">2022-09-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-11-24 21:43:31" itemprop="dateModified" datetime="2023-11-24T21:43:31+08:00">2023-11-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/" itemprop="url" rel="index"><span itemprop="name">科研</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB/" itemprop="url" rel="index"><span itemprop="name">加密流量分类</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="0、摘要"><a href="#0、摘要" class="headerlink" title="0、摘要"></a>0、摘要</h1><p> &emsp;&emsp;FS-Net是一个端到端的分类模型，它从原始流中学习代表性特征，然后在一个统一的框架中对它们进行分类。采用多层编码器-解码器结构，可以深入挖掘流的潜在序列特征，并引入重构机制，提高特征的有效性。</p>
<h1 id="1、问题引入"><a href="#1、问题引入" class="headerlink" title="1、问题引入"></a>1、问题引入</h1><p> &emsp;&emsp;传统的基于统计特征加上机器学习的流量分类，太依赖与专业经验，即人类的特征工程，特征工程的好坏直接影响分类性能。以往的基于DL的流量分类方法如<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_45125356/article/details/126661237?spm=1001.2014.3001.5501">Deep Packet:</a>，只使用了网络流量的有效载荷进行分类，没有考虑到流量中的其他信息。因此提出基于DL的端到端的分类模型，尝试设计一种新的适合<strong>流序列特征</strong>的神经网络结构，可以直接从原始输入中学习特征，学习到的特征以真实标签为指导，从而提高性能。因此，它可以节省设计和验证功能的人力。</p>
<h1 id="2、问题定义"><a href="#2、问题定义" class="headerlink" title="2、问题定义"></a>2、问题定义</h1><ul>
<li>FS-Net是基于网络流量的应用分类，即应用识别。</li>
<li><p>一个原始流量可以表示为不同的类型序列，如消息类型序列或者<strong>包长度序列</strong>，本文将一个原始流量看作包长度序列。具体的，Xp表示第p个样本的序列表示：</p>
<script type="math/tex; mode=display">
X_p=[L_1^p,L_2^p,...,L_n^p)]</script><p>其中n是Xp的长度，L~i~^p^是时间步长i的数据包值。</p>
<h1 id="3、模型结构"><a href="#3、模型结构" class="headerlink" title="3、模型结构"></a>3、模型结构</h1><h2 id="3-1总览"><a href="#3-1总览" class="headerlink" title="3.1总览"></a>3.1总览</h2><p>类似于AE半监督的思想，模型由五大块组成</p>
<ul>
<li>嵌入层</li>
<li>编码层</li>
<li>解码层</li>
<li>重构层</li>
<li>分类器<br><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311241039729.png" alt="模型整体结构"></li>
</ul>
<h2 id="3-2-嵌入层"><a href="#3-2-嵌入层" class="headerlink" title="3.2 嵌入层"></a>3.2 嵌入层</h2><p>&emsp;&emsp;</p>
<ul>
<li>任务：将L~1~到L~n~的序列信息转化为e~1~到e~n~的向量表示。如果有K个数据，且嵌入向量的维度为d，那么K个数据经过嵌入层将转化为一个矩阵E^K*d^,矩阵E是可以在模型训练过程中训练出来的，矩阵的每一个行向量都对应着一个数据样本的嵌入向量表示。</li>
<li><p>使用嵌入向量的优点：</p>
<ol>
<li>一些非数值(如消息类型)可以很容易地表示为数值进行计算。</li>
<li>向量表示丰富了一个序列中每个元素保存的信息。嵌入向量的每个维度都是影响流生成的潜在特征。同一元素在不同的序列中可能有不同的含义和方面。</li>
<li>模型可以学习每个元素的嵌入向量的面向任务的较优秀的向量表示，从而提高分类性能。<h2 id="3-3-编码层"><a href="#3-3-编码层" class="headerlink" title="3.3 编码层"></a>3.3 编码层</h2></li>
</ol>
</li>
<li>输入为嵌入向量，输出压缩后的特征</li>
<li>编码采用的是堆叠的Bi-GRU神经网络模型。低层的编码器学习到局部特征，高层的编码器学习到相对全局的特征，最后将<strong>所有层的最终前向与后向的隐藏状态串联</strong>Z~e~作为编码器压缩后的特征。此时，Z~e~就包含了整个编码流程序列的双向上下文信息，将会作为分类器的输入的一部分。（既有局部的，又有全局的）<h2 id="3-4-解码层"><a href="#3-4-解码层" class="headerlink" title="3.4 解码层"></a>3.4 解码层</h2></li>
<li>解码器的结构如同编码器一样，为折叠的Bi-GRU网络结构。</li>
<li><p>输入为Z~e~，输出由两个部分组成</p>
<p> 1.第一部分类似于编码器的输出，为解码器所有层的前向状态与后向状态的拼接，称之为，Z~d~这部分输出将会作用与最终的分类器输出的一部分。<br> 2.第二部分则是最后一层解码器的自身输出，这部分将会送入重构层，进行重构，重构目标是还原起初的模型输入。</p>
<h2 id="3-5-分类器"><a href="#3-5-分类器" class="headerlink" title="3.5 分类器"></a>3.5 分类器</h2></li>
</ul>
</li>
<li>分类器之前，设置了<strong>Dense层</strong>对分类器的输入（即Z~e~与Z~d~向量的拼接）进行压缩，得到新的特征向量z.<br><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311241039676.png" alt="压缩公式"><br>然而，z的维度还是太高，使用两层带Selu的激活函数的MLP对z进行降维得到Z~c~,降维过后能有效避免过拟合问题。<br><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311241039822.png" alt="降维"><br>公式中的W1，b1,b2都是可以学习的参数。</li>
<li>输入为Z~c~，经过softmax分类器，得到预测标签A^-^，与真实标签A之间构造一个交叉熵损失L~C~</li>
<li>在重构器后面，解码器中的Bi-GRU经过重构，输出的L~i^~与原始的输入特征L~i~之间可以构造另外一个交叉熵损失L~R~</li>
<li><p>因此，最终的损失函数</p>
<script type="math/tex; mode=display">
L=L_C+αL_R</script><p>α是超参数。</p>
<h1 id="4、实验"><a href="#4、实验" class="headerlink" title="4、实验"></a>4、实验</h1><ul>
<li><strong>实验设置</strong>：以报文长度序列作为FS-Net的输出，嵌入向量维度d设置为128，GRU的隐藏状态维度也是128，α设置为1，dropout设置为0.3，Adam优化器的lr设置为0.0005</li>
<li><strong>与其他模型结果实验对比的结论</strong>：加密流分类任务中，报文长度比消息类型更具有代表性。主要原因可能是[11]发现的不同应用程序的消息类型序列高度重叠。有更多的信息蕴含在包长度集合中而不是消息类型的集合中。</li>
<li><p><strong>对FS-Net的一些分析</strong>：</p>
<ol>
<li>摒弃解码器层、重构层和重构损失，即只将基于编码器的特征向量Z~e~传递到密集层进行分类。该变体称为FS-ND.此时FS-Net与其变体FS-ND的默认输入仍旧为<strong>包长度序列（The packet length sequence）</strong>。<blockquote>
<p>个人感觉这种变体特别像BERT，BERT就是只使用了Transformer的编码器结构，经历预训练后，在诸多下游任务中均获得了不错的效果。当然，BERT是有MLM与NSP的预训练任务的，而此处的FS-ND貌似并没有提及，只是单纯砍掉了解码器与重构器那一部分。</p>
</blockquote>
</li>
<li>因为传统的消息类型马尔可夫方法(FoSM、SOCRT、SOB)以<strong>消息类型序列（The message type sequences）</strong>作为输入。为了便于比较，FS-Net和FS-ND也结合消息类型序列进行测试，对应的方法记为FS-Net- s和FS-ND- s。</li>
<li>采用多属性序列(消息类型序列和报文长度序列)来提高性能。即同时关注<strong>包长度序列（The packet length sequence）</strong>与<strong>消息类型序列（The message type sequences）</strong>，这两种不同的模型被称为FS-Net-SL和FS-ND-SL。<br><img src="https://img-blog.csdnimg.cn/51ff895315324d16b5adc84b28e2dbbb.png" alt="实验结构"></li>
</ol>
<ul>
<li><strong>结果分析</strong>：<ol>
<li><strong>重构机制（即包含解码层、重构层）有用</strong>，提高分类性能。与不同序列比较，FS-Net的FTF性能始终优于FS-ND，提高了0.01左右。利用重构机制，引导从编码器学习到的特征存储更丰富的信息。</li>
<li><strong>重构机制有用，但是对比FS-ND提示不大，并且加了那么多结构，有点不太划算</strong>。变体模型FS-ND也优于现有的模型，而且FS-Net和FS-ND之间的性能差距不大。然而，FS-ND模型比FS-Net需要更少的层，可以更快地训练。</li>
<li><strong>报文长度序列的信息比消息类型序列的信息更丰富</strong>。消息类型序列的信息几乎被合并到包长度序列中。从FS-Net到FS-Net- sl的改进不显著(如FTF为0.0005)。FSND和FS-ND-SL之间也存在类似的现象。</li>
</ol>
</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>调参分析</strong>：</p>
<ol>
<li><strong>GRU的隐藏状态维度</strong>：太大，模型冗余，过拟合的同时容易从噪声中学习无用信息；太小，不足以提取数据的隐藏特征。研究中设置为128。</li>
<li><strong>超参数α</strong>：建议α值设为[0.125,2]。<h1 id="5、总结与思考"><a href="#5、总结与思考" class="headerlink" title="5、总结与思考"></a>5、总结与思考</h1></li>
</ol>
</li>
<li>模型结构，类似与NLP中的Seq2Seq结构，可否在中间的编码器与解码器之间照葫芦画瓢加上Attention机制来进一步优化捏？</li>
<li>去除解码器与重构器，模型复杂度减少，并且实验证明在数据集上的表现FS-ND也跟FS-Net差之无几，能否在FS-ND上做出改进，使之效率与复杂度要比现在的模型好。</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="luluX"
      src="/images/ava.jpg">
  <p class="site-author-name" itemprop="name">luluX</p>
  <div class="site-description" itemprop="description">lulu-cloud的个人GitHub博客</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">32</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">分类</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/lulu-cloud" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;lulu-cloud" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://blog.csdn.net/qq_45125356?spm=1001.2101.3001.5343" title="https:&#x2F;&#x2F;blog.csdn.net&#x2F;qq_45125356?spm&#x3D;1001.2101.3001.5343" rel="noopener" target="_blank">CSDN博客</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">luluX</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
