<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hexo</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://lulu-cloud.github.io/"/>
  <updated>2023-11-24T08:28:55.290Z</updated>
  <id>https://lulu-cloud.github.io/</id>
  
  <author>
    <name>lulu-cloud</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>疯狂的横向-开题期间</title>
    <link href="https://lulu-cloud.github.io/2023/11/23/%E5%BC%80%E9%A2%98%E3%80%81%E7%A7%91%E7%A0%94%E4%B8%8E%E6%A8%AA%E5%90%91/"/>
    <id>https://lulu-cloud.github.io/2023/11/23/开题、科研与横向/</id>
    <published>2023-11-23T13:42:14.000Z</published>
    <updated>2023-11-24T08:28:55.290Z</updated>
    
    <content type="html"><![CDATA[<ol><li>狠狠滴看领域内的论文，编开题报告！！</li><li>横向横向横向，每次会议的主题。无语辣。</li><li>听首歌，只想那种积极的，听得我爽就好，邓紫棋的《再见》</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ol&gt;
&lt;li&gt;狠狠滴看领域内的论文，编开题报告！！&lt;/li&gt;
&lt;li&gt;横向横向横向，每次会议的主题。无语辣。&lt;/li&gt;
&lt;li&gt;听首歌，只想那种积极的，听得我爽就好，邓紫棋的《再见》&lt;/li&gt;
&lt;/ol&gt;

      
    
    </summary>
    
      <category term="硕士生活" scheme="https://lulu-cloud.github.io/categories/%E7%A1%95%E5%A3%AB%E7%94%9F%E6%B4%BB/"/>
    
    
      <category term="生活随记" scheme="https://lulu-cloud.github.io/tags/%E7%94%9F%E6%B4%BB%E9%9A%8F%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>加密流量分类-论文4:Endtoend Encrypted Traffic Classification with One-dimensional Convolution Neural Networks</title>
    <link href="https://lulu-cloud.github.io/2022/09/18/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB-%E8%AE%BA%E6%96%874%EF%BC%9AEndtoend%20Encrypted%20Traffic%20Classification%20with%20One-dimensional%20Convolution%20Neural%20Networks/"/>
    <id>https://lulu-cloud.github.io/2022/09/18/加密流量分类-论文4：Endtoend Encrypted Traffic Classification with One-dimensional Convolution Neural Networks/</id>
    <published>2022-09-18T13:27:14.000Z</published>
    <updated>2023-11-24T13:04:50.451Z</updated>
    
    <content type="html"><![CDATA[<h1 id="0、摘要"><a href="#0、摘要" class="headerlink" title="0、摘要"></a>0、摘要</h1><p>&emsp;&emsp;此篇方法是第一个将端到端的方法应用到加密流量分类领域，使用数据集ISCX-VPN-NonVPN-2016数据集进行研究。</p><h1 id="1、概念介绍"><a href="#1、概念介绍" class="headerlink" title="1、概念介绍"></a>1、概念介绍</h1><h2 id="1-1-流量加密技术"><a href="#1-1-流量加密技术" class="headerlink" title="1.1 流量加密技术"></a>1.1 流量加密技术</h2><p>&emsp;&emsp;依据ISO/OSI层的不同，加密技术可以分为</p><ul><li><p>应用层加密：应用程序在应用层实现自己的协议以实现数据的安全传输(如BitTorrent或Skype)，在一些论文中也称为常规加密。</p></li><li><p>表示层加密</p></li><li><p>网络层加密：如IPSec加密协议</p></li></ul><h2 id="1-2-常见加密协议"><a href="#1-2-常见加密协议" class="headerlink" title="1.2 常见加密协议"></a>1.2 常见加密协议</h2><ul><li>IPSec协议：网络层加密协议。分为<strong>传输</strong>与<strong>隧道</strong>两种模式<ul><li>传输模式：在IP报头和高层协议报头中插入一个IPSec报头，该模式不会改变IP报头中的目的地址，源IP地址也保持明文状态。</li><li>隧道模式：报文的源IP地址以及数据被封装成一个新的IP报文，并在内部和外部报头之间插入一个IPSec报头，原来的IP地址作为需要进行安全业务处理的一部分来提供安全保护，并且该模式下，可以对整个IP报文进行加密操作，常用来实现<strong>虚拟专用网VPN</strong>。</li></ul></li><li>SSL/TLS协议：传输层协议。对于TLS，简单地说，是在TCP层之上再封装了SSL层。安全套接层协议 SSL 提供应用层和传输层之间的数据安全性机制，在客户端和 服务器之间建立安全通道，对数据进行加密和隐藏，确保数据在传输过程中不被改变。 SSL 协议在应用层协议通信之前就已经完成加密算法和密钥的协商，在此之后所传送的 数据都会被加密，从而保证通信的私密性。</li><li>HTTPS协议：应用层加密协议。HTTPS中，通信协议使用安全传输层TLS或者SSL进行加密。</li><li>QUIC协议：应用层加密协议。全称（Quick UDP Internet Connection），是谷歌制定的一种基于UDP的低时延的互联网传输层协议。QUIC融合了包括TCP、TLS、HTTP/2.0等协议的特性，但是基于<strong>UDP</strong>传输，主要目标就是<strong>减少连接延迟</strong>，避免HTTP/2.0的线头阻塞（Head-of-Line Blocking）问题。</li></ul><h2 id="1-3-端到端的流量分类方法与传统方法的对比"><a href="#1-3-端到端的流量分类方法与传统方法的对比" class="headerlink" title="1.3 端到端的流量分类方法与传统方法的对比"></a>1.3 端到端的流量分类方法与传统方法的对比</h2><p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242102745.png" alt="方法对比"></p><ul><li>传统的分类方法流程：从原始流量中，经过人类专家精心设计的特征工程模块进行特征提取，形成基于流级（flow）或者包级（packet）的特征，最后送入分类器进行分类（一般是传统的基于机器学习的分类模型，如LR、SVM、C4.5等分类器）</li><li>端到端的分类方法流程：从原始流量直接进入模型，映射到它对应的label。</li></ul><h2 id="1-4-网络流量划分粒度"><a href="#1-4-网络流量划分粒度" class="headerlink" title="1.4 网络流量划分粒度"></a>1.4 网络流量划分粒度</h2><p>&emsp;&emsp;不同的拆分粒度会导致不同的流量单位。主流的研究分为包级（packet）、流级（flow）、会话级（session）</p><ul><li><p>原始流量（raw traffic）可以定义为|P|个包的集合</p><script type="math/tex; mode=display">P=\{p^1,...p^{|P|}\}</script><p>其中，</p><script type="math/tex; mode=display">p^i=(x^i,b^i,t^i),i=1,2,...,|P|</script><ul><li>第一个分量xi 表示五元组(源IP、源端口、目的IP、目的端口和传输级协议)</li><li>第二个分量bi表示包的长度，单位是字节（byte）</li><li>第三个分量ti表示当前包开始传输的时间</li></ul></li><li><p>流级：一组原始流量P可以划分为多个子集，子集中的所有数据包按照时间排列，每一个子集就称为一个流（flow）</p><script type="math/tex; mode=display">f=(x,b,d,t)=\{p^1=(x^1,b^1,t^1),p^2=(x^2,b^2,t^2),...,p^n=(x^n,b^n,t^n)\},  t^1<...<t^n</script><ul><li>x表示流中所有包的五元组（都是相同的）</li><li>b表示流中所有包的字节总和</li><li>d表示流持续时间，可以表示为d=tn-t1</li><li>t则是流中第一个数据包开始发送的时间</li></ul></li><li>会话级：一个会话可以定义为双向流，即流的五元组中的源IP/源port与目的IP/目的port可以互换(session)</li></ul><h1 id="2、ISCX-VPN-NonVPN-2016数据集"><a href="#2、ISCX-VPN-NonVPN-2016数据集" class="headerlink" title="2、ISCX-VPN-NonVPN-2016数据集"></a>2、ISCX-VPN-NonVPN-2016数据集</h1><ul><li><p>ISCX-VPN-NonVPN-2016包括7种常规加密流量和7种协议封装流量</p><p>数据集结构如下：</p><p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242102172.png" alt="ISCX数据集概览"></p></li></ul><ul><li><p>ISCX数据集的流特征有14类标签，但原始流量没有标签，因此我们根据数据集中pcap文件的论文描述对其进行标签。而一些文件，如Facebook_video.pcap可以被标记为“浏览器”或“流媒体”，所有与“浏览器”和“vpn -浏览器”相关的文件都有这个问题。决定不给这些文件贴上标签。</p><p>最后，标记的ISCX数据集有12类，包括6类常规加密流量和6类协议封装流量。</p><h1 id="3、模型结构"><a href="#3、模型结构" class="headerlink" title="3、模型结构"></a>3、模型结构</h1><h2 id="3-1总览"><a href="#3-1总览" class="headerlink" title="3.1总览"></a>3.1总览</h2></li></ul><p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242102715.png" alt="模型概览"></p><h2 id="3-2-数据预处理"><a href="#3-2-数据预处理" class="headerlink" title="3.2 数据预处理"></a>3.2 数据预处理</h2><p> &emsp;&emsp;使用论文团队开发的工具USTC-TL2016进行数据预处理</p><ul><li><p>流量分割：这个步骤将一个连续的原始流量分割为多个离散的流量单元。输入数据格式为pcap。如果表示类型为Flow + All或Session + All，则输出数据格式为pcap。当表示类型为Flow + L7或Session + L7时，输出数据格式为bin。即.pacp 转化为.pacp或者.bin。</p><ul><li><p>ALL表示使用了所有层的包层选择</p></li><li><p>L7表示仅仅使用了OSI模型的第七层（应用层）的包层选择</p></li></ul></li><li>流量清理：对数据链路层和IP层的MAC地址和IP地址分别进行随机化。</li><li>图像生成（非必要）：将所有文件修剪为统一的长度。如果文件大小大于784字节，则裁剪为784字节。如果文件大小小于784字节，则在最后添加0x00以补充到784字节。然后，具有相同大小的结果文件被转换为灰色图像。原始文件的每个字节代表一个像素，例如0x00是黑色的，0xff是白色的。这种转换是可选的，可以简单地直接将文件转换为IDX文件。</li><li><p>IDX转换：此步骤将图像转换为IDX格式文件，IDX文件包含一组图像的所有像素和统计信息。IDX格式是机器学习领域中常用的文件格式。</p><h2 id="3-3-训练阶段"><a href="#3-3-训练阶段" class="headerlink" title="3.3 训练阶段"></a>3.3 训练阶段</h2><p>&emsp;&emsp;采用小批量随机梯度下降(SGD)。采用10倍交叉验证技术，保证了CNN模型的泛化能力。</p><h2 id="3-4-测试阶段"><a href="#3-4-测试阶段" class="headerlink" title="3.4 测试阶段"></a>3.4 测试阶段</h2><p>&emsp;&emsp;利用训练好的CNN模型进行测试</p><h2 id="3-5-1D-CNN模型"><a href="#3-5-1D-CNN模型" class="headerlink" title="3.5 1D-CNN模型"></a>3.5 1D-CNN模型</h2></li><li><p>输入：取流或者会话的前n个字节作为模型输入，n取784（28*28）</p></li><li><p>使用1D-CNN的理由：CNN主要应用于计算机视觉领域，如图像分类。CNN适用于以下类型的数据:</p><ul><li><p>多数组形式的数据;</p></li><li><p>具有强局部相关性的数据;</p></li><li><p>特征可以出现在任何地方的数据;</p></li><li><p>对象不受平移和扭曲影响的数据。</p></li></ul></li></ul><p>具体来说，1D-CNN适合于诸如顺序数据或语言之类的数据。2D-CNN适用于图像或音频声谱图等数据。3D-CNN适用于视频或体积图像等数据。网络流量本质上是顺序数据。它是一种按层次结构组织的一维字节流。字节、分组、会话和整个流量的结构与自然语言处理领域中的字符、单词、句子和整篇文章的结构非常相似。近年来，CNN在NLP中的成功应用均采用1D-CNN，如情感分析、文本分类。本文在这些研究的启发下，使用一维cnn执行加密流量分类任务，并将其性能与二维cnn进行比较。</p><h1 id="4、实验"><a href="#4、实验" class="headerlink" title="4、实验"></a>4、实验</h1><ul><li><p><strong>模型参数</strong>：</p><p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242102167.png" alt="模型参数"></p></li></ul><ul><li><p><strong>超参数设置</strong>：</p><p>epoch：40</p><p>learn_rating: 1.0e-4</p><p>batch_size: 50</p></li><li><p><strong>实验结果</strong>：<br><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311242103515.png" alt="论文实验结果"></p><blockquote><p>论文给出的源码是基于tensorflow实现的，这里用torch写了一个CNN做了一下exp4，也就是上图的红色箭头的结果。如下,基本差不多<br><img src="https://img-blog.csdnimg.cn/f2a88816192042128862e4a3d3dc2e61.jpeg#pic_center" alt="torch复现"></p></blockquote></li></ul><pre><code>class OneCNNC(nn.Module):    def __init__(self,label_num):        super(OneCNNC,self).__init__()        self.layer_1 = nn.Sequential(            # 输入784*1            nn.Conv2d(1,32,(1,25),1,padding=&#39;same&#39;),            nn.ReLU(),            # 输出262*32            nn.MaxPool2d((1, 3), 3, padding=(0,1)),        )        self.layer_2 = nn.Sequential(            # 输入262*32            nn.Conv2d(32,64,(1,25),1,padding=&#39;same&#39;),            nn.ReLU(),            # 输入262*64            nn.MaxPool2d((1, 3), 3, padding=(0,1))        )        self.fc1=nn.Sequential(            # 输入88*64            nn.Flatten(),            nn.Linear(88*64,1024),            # 这里自己加了两个dropout层            nn.Dropout(p=0.5),            nn.Linear(1024,label_num),            nn.Dropout(p=0.3)        )    def forward(self,x):        # print(&quot;x.shape:&quot;,x.shape)        x=self.layer_1(x)        # print(&quot;x.shape:&quot;,x.shape)        x=self.layer_2(x)        # print(&quot;x.shape:&quot;,x.shape)        x=self.fc1(x)        # print(&quot;x.shape:&quot;,x.shape)        return x</code></pre><ul><li><strong>对比分析</strong>：<ol><li><strong>与2D-CNN的对比</strong></li><li><strong>与C4.5分类器的对比</strong><h1 id="5、总结与思考"><a href="#5、总结与思考" class="headerlink" title="5、总结与思考"></a>5、总结与思考</h1></li></ol></li><li>学习一下流量数据的预处理套路</li><li>第一个端到端的基于神经网络的分类模型？1D-CNN结果简单，分类效果好，基于深度学习的方法在流量分类中有巨大潜力。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;0、摘要&quot;&gt;&lt;a href=&quot;#0、摘要&quot; class=&quot;headerlink&quot; title=&quot;0、摘要&quot;&gt;&lt;/a&gt;0、摘要&lt;/h1&gt;&lt;p&gt;&amp;emsp;&amp;emsp;此篇方法是第一个将端到端的方法应用到加密流量分类领域，使用数据集ISCX-VPN-NonVPN-20
      
    
    </summary>
    
      <category term="科研" scheme="https://lulu-cloud.github.io/categories/%E7%A7%91%E7%A0%94/"/>
    
      <category term="加密流量分类" scheme="https://lulu-cloud.github.io/categories/%E7%A7%91%E7%A0%94/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB/"/>
    
    
      <category term="论文" scheme="https://lulu-cloud.github.io/tags/%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>加密流量分类-论文3: FS-Net_ A Flow Sequence Network For Encrypted Traffic Classification</title>
    <link href="https://lulu-cloud.github.io/2022/09/04/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB-%E8%AE%BA%E6%96%873%EF%BC%9AFS-Net_%20A%20Flow%20Sequence%20Network%20For%20Encrypted%20Traffic%20Classification/"/>
    <id>https://lulu-cloud.github.io/2022/09/04/加密流量分类-论文3：FS-Net_ A Flow Sequence Network For Encrypted Traffic Classification/</id>
    <published>2022-09-04T13:27:14.000Z</published>
    <updated>2023-11-24T13:04:38.318Z</updated>
    
    <content type="html"><![CDATA[<h1 id="0、摘要"><a href="#0、摘要" class="headerlink" title="0、摘要"></a>0、摘要</h1><p> &emsp;&emsp;FS-Net是一个端到端的分类模型，它从原始流中学习代表性特征，然后在一个统一的框架中对它们进行分类。采用多层编码器-解码器结构，可以深入挖掘流的潜在序列特征，并引入重构机制，提高特征的有效性。</p><h1 id="1、问题引入"><a href="#1、问题引入" class="headerlink" title="1、问题引入"></a>1、问题引入</h1><p> &emsp;&emsp;传统的基于统计特征加上机器学习的流量分类，太依赖与专业经验，即人类的特征工程，特征工程的好坏直接影响分类性能。以往的基于DL的流量分类方法如<a href="https://blog.csdn.net/qq_45125356/article/details/126661237?spm=1001.2014.3001.5501">Deep Packet:</a>，只使用了网络流量的有效载荷进行分类，没有考虑到流量中的其他信息。因此提出基于DL的端到端的分类模型，尝试设计一种新的适合<strong>流序列特征</strong>的神经网络结构，可以直接从原始输入中学习特征，学习到的特征以真实标签为指导，从而提高性能。因此，它可以节省设计和验证功能的人力。</p><h1 id="2、问题定义"><a href="#2、问题定义" class="headerlink" title="2、问题定义"></a>2、问题定义</h1><ul><li>FS-Net是基于网络流量的应用分类，即应用识别。</li><li><p>一个原始流量可以表示为不同的类型序列，如消息类型序列或者<strong>包长度序列</strong>，本文将一个原始流量看作包长度序列。具体的，Xp表示第p个样本的序列表示：</p><script type="math/tex; mode=display">X_p=[L_1^p,L_2^p,...,L_n^p)]</script><p>其中n是Xp的长度，L~i~^p^是时间步长i的数据包值。</p><h1 id="3、模型结构"><a href="#3、模型结构" class="headerlink" title="3、模型结构"></a>3、模型结构</h1><h2 id="3-1总览"><a href="#3-1总览" class="headerlink" title="3.1总览"></a>3.1总览</h2><p>类似于AE半监督的思想，模型由五大块组成</p><ul><li>嵌入层</li><li>编码层</li><li>解码层</li><li>重构层</li><li>分类器<br><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311241039729.png" alt="模型整体结构"></li></ul><h2 id="3-2-嵌入层"><a href="#3-2-嵌入层" class="headerlink" title="3.2 嵌入层"></a>3.2 嵌入层</h2><p>&emsp;&emsp;</p><ul><li>任务：将L~1~到L~n~的序列信息转化为e~1~到e~n~的向量表示。如果有K个数据，且嵌入向量的维度为d，那么K个数据经过嵌入层将转化为一个矩阵E^K*d^,矩阵E是可以在模型训练过程中训练出来的，矩阵的每一个行向量都对应着一个数据样本的嵌入向量表示。</li><li><p>使用嵌入向量的优点：</p><ol><li>一些非数值(如消息类型)可以很容易地表示为数值进行计算。</li><li>向量表示丰富了一个序列中每个元素保存的信息。嵌入向量的每个维度都是影响流生成的潜在特征。同一元素在不同的序列中可能有不同的含义和方面。</li><li>模型可以学习每个元素的嵌入向量的面向任务的较优秀的向量表示，从而提高分类性能。<h2 id="3-3-编码层"><a href="#3-3-编码层" class="headerlink" title="3.3 编码层"></a>3.3 编码层</h2></li></ol></li><li>输入为嵌入向量，输出压缩后的特征</li><li>编码采用的是堆叠的Bi-GRU神经网络模型。低层的编码器学习到局部特征，高层的编码器学习到相对全局的特征，最后将<strong>所有层的最终前向与后向的隐藏状态串联</strong>Z~e~作为编码器压缩后的特征。此时，Z~e~就包含了整个编码流程序列的双向上下文信息，将会作为分类器的输入的一部分。（既有局部的，又有全局的）<h2 id="3-4-解码层"><a href="#3-4-解码层" class="headerlink" title="3.4 解码层"></a>3.4 解码层</h2></li><li>解码器的结构如同编码器一样，为折叠的Bi-GRU网络结构。</li><li><p>输入为Z~e~，输出由两个部分组成</p><p> 1.第一部分类似于编码器的输出，为解码器所有层的前向状态与后向状态的拼接，称之为，Z~d~这部分输出将会作用与最终的分类器输出的一部分。<br> 2.第二部分则是最后一层解码器的自身输出，这部分将会送入重构层，进行重构，重构目标是还原起初的模型输入。</p><h2 id="3-5-分类器"><a href="#3-5-分类器" class="headerlink" title="3.5 分类器"></a>3.5 分类器</h2></li></ul></li><li>分类器之前，设置了<strong>Dense层</strong>对分类器的输入（即Z~e~与Z~d~向量的拼接）进行压缩，得到新的特征向量z.<br><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311241039676.png" alt="压缩公式"><br>然而，z的维度还是太高，使用两层带Selu的激活函数的MLP对z进行降维得到Z~c~,降维过后能有效避免过拟合问题。<br><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311241039822.png" alt="降维"><br>公式中的W1，b1,b2都是可以学习的参数。</li><li>输入为Z~c~，经过softmax分类器，得到预测标签A^-^，与真实标签A之间构造一个交叉熵损失L~C~</li><li>在重构器后面，解码器中的Bi-GRU经过重构，输出的L~i^~与原始的输入特征L~i~之间可以构造另外一个交叉熵损失L~R~</li><li><p>因此，最终的损失函数</p><script type="math/tex; mode=display">L=L_C+αL_R</script><p>α是超参数。</p><h1 id="4、实验"><a href="#4、实验" class="headerlink" title="4、实验"></a>4、实验</h1><ul><li><strong>实验设置</strong>：以报文长度序列作为FS-Net的输出，嵌入向量维度d设置为128，GRU的隐藏状态维度也是128，α设置为1，dropout设置为0.3，Adam优化器的lr设置为0.0005</li><li><strong>与其他模型结果实验对比的结论</strong>：加密流分类任务中，报文长度比消息类型更具有代表性。主要原因可能是[11]发现的不同应用程序的消息类型序列高度重叠。有更多的信息蕴含在包长度集合中而不是消息类型的集合中。</li><li><p><strong>对FS-Net的一些分析</strong>：</p><ol><li>摒弃解码器层、重构层和重构损失，即只将基于编码器的特征向量Z~e~传递到密集层进行分类。该变体称为FS-ND.此时FS-Net与其变体FS-ND的默认输入仍旧为<strong>包长度序列（The packet length sequence）</strong>。<blockquote><p>个人感觉这种变体特别像BERT，BERT就是只使用了Transformer的编码器结构，经历预训练后，在诸多下游任务中均获得了不错的效果。当然，BERT是有MLM与NSP的预训练任务的，而此处的FS-ND貌似并没有提及，只是单纯砍掉了解码器与重构器那一部分。</p></blockquote></li><li>因为传统的消息类型马尔可夫方法(FoSM、SOCRT、SOB)以<strong>消息类型序列（The message type sequences）</strong>作为输入。为了便于比较，FS-Net和FS-ND也结合消息类型序列进行测试，对应的方法记为FS-Net- s和FS-ND- s。</li><li>采用多属性序列(消息类型序列和报文长度序列)来提高性能。即同时关注<strong>包长度序列（The packet length sequence）</strong>与<strong>消息类型序列（The message type sequences）</strong>，这两种不同的模型被称为FS-Net-SL和FS-ND-SL。<br><img src="https://img-blog.csdnimg.cn/51ff895315324d16b5adc84b28e2dbbb.png" alt="实验结构"></li></ol><ul><li><strong>结果分析</strong>：<ol><li><strong>重构机制（即包含解码层、重构层）有用</strong>，提高分类性能。与不同序列比较，FS-Net的FTF性能始终优于FS-ND，提高了0.01左右。利用重构机制，引导从编码器学习到的特征存储更丰富的信息。</li><li><strong>重构机制有用，但是对比FS-ND提示不大，并且加了那么多结构，有点不太划算</strong>。变体模型FS-ND也优于现有的模型，而且FS-Net和FS-ND之间的性能差距不大。然而，FS-ND模型比FS-Net需要更少的层，可以更快地训练。</li><li><strong>报文长度序列的信息比消息类型序列的信息更丰富</strong>。消息类型序列的信息几乎被合并到包长度序列中。从FS-Net到FS-Net- sl的改进不显著(如FTF为0.0005)。FSND和FS-ND-SL之间也存在类似的现象。</li></ol></li></ul></li></ul></li><li><p><strong>调参分析</strong>：</p><ol><li><strong>GRU的隐藏状态维度</strong>：太大，模型冗余，过拟合的同时容易从噪声中学习无用信息；太小，不足以提取数据的隐藏特征。研究中设置为128。</li><li><strong>超参数α</strong>：建议α值设为[0.125,2]。<h1 id="5、总结与思考"><a href="#5、总结与思考" class="headerlink" title="5、总结与思考"></a>5、总结与思考</h1></li></ol></li><li>模型结构，类似与NLP中的Seq2Seq结构，可否在中间的编码器与解码器之间照葫芦画瓢加上Attention机制来进一步优化捏？</li><li>去除解码器与重构器，模型复杂度减少，并且实验证明在数据集上的表现FS-ND也跟FS-Net差之无几，能否在FS-ND上做出改进，使之效率与复杂度要比现在的模型好。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;0、摘要&quot;&gt;&lt;a href=&quot;#0、摘要&quot; class=&quot;headerlink&quot; title=&quot;0、摘要&quot;&gt;&lt;/a&gt;0、摘要&lt;/h1&gt;&lt;p&gt; &amp;emsp;&amp;emsp;FS-Net是一个端到端的分类模型，它从原始流中学习代表性特征，然后在一个统一的框架中对它们进行分
      
    
    </summary>
    
      <category term="科研" scheme="https://lulu-cloud.github.io/categories/%E7%A7%91%E7%A0%94/"/>
    
      <category term="加密流量分类" scheme="https://lulu-cloud.github.io/categories/%E7%A7%91%E7%A0%94/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB/"/>
    
    
      <category term="论文" scheme="https://lulu-cloud.github.io/tags/%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>加密流量分类-论文2: Deep Packet_ A Novel Approach For Encrypted Traffic Classification Using Deep Learning</title>
    <link href="https://lulu-cloud.github.io/2022/09/02/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB-%E8%AE%BA%E6%96%872%EF%BC%9ADeep%20Packet_%20A%20Novel%20Approach%20For%20Encrypted%20Traffic%20Classification%20Using%20Deep%20Learning/"/>
    <id>https://lulu-cloud.github.io/2022/09/02/加密流量分类-论文2：Deep Packet_ A Novel Approach For Encrypted Traffic Classification Using Deep Learning/</id>
    <published>2022-09-02T13:27:14.000Z</published>
    <updated>2023-11-24T13:04:24.900Z</updated>
    
    <content type="html"><![CDATA[<h1 id="0、摘要"><a href="#0、摘要" class="headerlink" title="0、摘要"></a>0、摘要</h1><p>&emsp;&emsp;论文提出的方案称为“深度包”(deep packet)，可以处理网络流量分类为主要类别(如FTP和P2P)的流量表征，以及需要终端用户应用程序(如BitTorrent和Skype)识别的应用程序识别。与现有的大多数方法不同，深度报文不仅可以识别加密流量，还可以区分VPN网络流量和非VPN网络流量。网络架构基于CNN与SAE，能同时进行<strong>应用识别</strong>与<strong>流量类型</strong>的分类任务。</p><h1 id="1、介绍"><a href="#1、介绍" class="headerlink" title="1、介绍"></a>1、介绍</h1><p>&emsp;&emsp;准确的流量分类已成为提供适当的服务质量(quality of service, QoS)、异常检测等高级网络管理任务的先决条件之一。流量分类在与网络管理相关的学术界和工业界都引起了极大的兴趣。</p><p>&emsp;&emsp;本文贡献：</p><ul><li>在Deep Packet中，不需要专家来提取与网络流量相关的特征。这种方法省去了查找和提取特征的繁琐步骤。（只要是基于DL的方法都能做到这一点）</li><li>Deep Packet可以在两个粒度级别(应用程序识别和流量表征)上识别流量，并获得最先进的结果。</li><li><p>深度数据包可以准确地分类最难的一类应用程序，已知是P2P。</p><h1 id="2、相关工作"><a href="#2、相关工作" class="headerlink" title="2、相关工作"></a>2、相关工作</h1><p>&emsp;&emsp;等于是一个综述，概览了之前流量分类的一些方法以及它的适用性与优缺点。可以参考<a href="https://blog.csdn.net/qq_45125356/article/details/126592812?spm=1001.2014.3001.5502">论文解读1</a></p></li><li><p>Port-based approach（基于端口）：提取过程简单，端口号不受加密方案的影响。然而，端口混淆、网络地址转换(NAT)、端口转发、协议嵌入和端口随机分配的普遍存在大大降低了这种方法的准确性，<strong>目前已经不适用</strong>。</p></li><li>Payload Inspection Techniques（基于有效载荷）:即深度包检测（DPI）。</li><li>Statistical and machine learning approach（基于统计特征+机器学习方法）：这些方法依赖于流量的统计或时间序列特性，能够处理加密和未加密的流量。</li></ul><p>&emsp;&emsp;<strong>总之，以前的方法，特征提取阶段依赖于人类的特征工程，耗时、昂贵且出错率高。</strong></p><h1 id="3、深度学习背景"><a href="#3、深度学习背景" class="headerlink" title="3、深度学习背景"></a>3、深度学习背景</h1><p>&emsp;&emsp;依旧是综述，关于神经网络的。这里主要介绍了两种神经网络结构。</p><h2 id="3-1-自编码器（Autoencoder，AE）"><a href="#3-1-自编码器（Autoencoder，AE）" class="headerlink" title="3.1 自编码器（Autoencoder，AE）"></a>3.1 自编码器（Autoencoder，AE）</h2><p>&emsp;&emsp;AE是一种无监督框架。考虑一个训练集{x1, x2，…， xn}其中对于每个训练数据我们有xi∈Rn。自编码器目标定义为yi = xi，对于i∈{1,2，…， n}，即网络的输出等于输入。自动编码器试图学习数据集的压缩表示，即<strong>将高维数据通过编码器降维，然后降维后的数据通过解码器升维，输出尽量与输入相同。这样。降维后的数据则包含了原始输入数据的信息</strong>。一般地，编码器与解码器的结构都是对称的。<br><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311011127286.png" alt="AE结构"><br>&emsp;&emsp;在实践中，为了获得更好的性能，一般使用<strong>堆栈式自动编码器(SAE)</strong>。将多个自动编码器堆叠起来，每个编码器的输出都是连续层的输入，而连续层本身就是一个自动编码器。堆叠式自动编码器的训练过程采用贪婪的分层方式完成。首先，该方法训练网络的每一层，同时冻结其他层的权值。在训练完所有层之后，为了得到更准确的结果，对整个神经网络进行微调。在微调阶段，利用反向传播算法调整各层权重。此外，对于分类任务，可以在最后一层应用额外的softmax层。<br><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311011127399.png" alt="SAE"></p><h2 id="3-2-卷积神经网络-Convolutional-Neural-Network-CNN"><a href="#3-2-卷积神经网络-Convolutional-Neural-Network-CNN" class="headerlink" title="3.2 卷积神经网络(Convolutional Neural Network, CNN)"></a>3.2 卷积神经网络(Convolutional Neural Network, CNN)</h2><ul><li>卷积：进行特征抽取</li><li>池化：聚合低级特征，获得局部不变性，并且能降低网络训练与测试的参数量。<br>&emsp;&emsp;一维卷积神经网络（1D-CNNs）可以捕获网络数据包中相邻字节之间的空间依赖关系，从而找到每一类协议/应用程序的区别模式，从而对流量进行准确的分类。<h1 id="4、方法"><a href="#4、方法" class="headerlink" title="4、方法"></a>4、方法</h1><h2 id="4-1-数据集"><a href="#4-1-数据集" class="headerlink" title="4.1 数据集"></a>4.1 数据集</h2>&emsp;&emsp;<strong>ISCX VPN-nonVPN</strong>：该数据集实在数据链路层捕获的，因此，每个数据包都包含一个以太网报头、一个IP数据报报头、一个TCP/UDP报头。</li></ul><h2 id="4-2-预处理"><a href="#4-2-预处理" class="headerlink" title="4.2 预处理"></a>4.2 预处理</h2><ol><li>删除以太网报头</li><li>将UDP报头填充0至20字节长度（TCP通常具有20字节长度的报头，而UDP具有8字节长度的报头。为了使传输层的段一致，在UDP段的报头末尾注入0，使它们的长度与TCP报头相等）</li><li>屏蔽IP数据报报头的IP</li><li>删除不相关的数据包，例如没有负载的数据包（TCP握手时SYN、ACK设置为1以及FIN设置为1的数据包）或者DNS数据段（将url转为IP地址的）</li><li>将原始数据包转为字节向量</li><li>截断超过1500的向量，不足1500长度的填充0</li><li>将向量的每个元素除以255来规范化字节向量</li><li>针对样本不均衡问题，对样本更多的类进行欠采样，直到类相对平衡。<br><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311011127411.png" alt="每个类别中的样本数量"><h2 id="4-3-网络架构"><a href="#4-3-网络架构" class="headerlink" title="4.3 网络架构"></a>4.3 网络架构</h2><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311011127926.png" alt="Deep Packet网络架构"></li></ol><ul><li>关于SAE的部分：<br>由五个全连接层（FC）,分别由400、300、200、100和50个神经元组成。为防止过拟合问题，每层后采用dropout技术，dropout率为0.05。针对应用识别和流量表征任务，在SAE的最后一层，分别添加了一个包含17个神经元和12个神经元的softmax分类器。</li><li>关于CNN的部分：<br>包括两个连续的卷积层，然后是池化层。将二维张量压缩为一维矢量，并将其送入三层全连接神经元网络，该网络采用dropout技术以避免过拟合。最后，将类似于SAE架构的softmax分类器应用于分类任务。<br><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311011128167.png" alt="CNN架构"><br>CNN的超参数如下：<br><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311011128738.png" alt="CNN的超参数"><h1 id="5、实验"><a href="#5、实验" class="headerlink" title="5、实验"></a>5、实验</h1></li><li>对于CNN的调参，此处改变了两个卷积层的滤波器大小、滤波器数量和步幅。总共评估了116个应用识别和交通表征任务的加权平均F1分数模型。通过结果得出如下结论：<strong>对于流量分类任务，无法选择最优模型，因为“最优模型”的定义是不明确的，而且模型的精度和它的复杂性(即训练速度和测试速度)之间存在权衡</strong>。</li><li><strong>增加神经网络的复杂度并不一定会带来更好的性能</strong>。可能的原因有：<br>&emsp;&emsp;一个复杂的模型在训练阶段更容易遇到梯度消失问题，从而导致模型的<strong>欠拟合</strong>。<br>&emsp;&emsp; 一个学习模型变得更复杂，而训练数据的大小保持不变，就会出现<strong>过拟合</strong>问题。</li><li>该工作与Wang W, Zhu M, Wang J, Zeng X, Yang Z (2017)<br>End-to-end encrypted traffic classification with one-dimensional convolution neural networks. In: Intel-ligence and Security Informatics (ISI), 2017 IEEE International Conference on, IEEE. 的方法类似，但Wang等人在流量表征的任务上获得了100%的精度，可能的原因是<strong>预处理过程中没有屏蔽IP地址字段，导致模型仅仅用IP地址这一特征来进行分类</strong>。</li></ul><h1 id="6、总结"><a href="#6、总结" class="headerlink" title="6、总结"></a>6、总结</h1><p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311011128877.png" alt="总结"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;0、摘要&quot;&gt;&lt;a href=&quot;#0、摘要&quot; class=&quot;headerlink&quot; title=&quot;0、摘要&quot;&gt;&lt;/a&gt;0、摘要&lt;/h1&gt;&lt;p&gt;&amp;emsp;&amp;emsp;论文提出的方案称为“深度包”(deep packet)，可以处理网络流量分类为主要类别(如FTP和P
      
    
    </summary>
    
      <category term="科研" scheme="https://lulu-cloud.github.io/categories/%E7%A7%91%E7%A0%94/"/>
    
      <category term="加密流量分类" scheme="https://lulu-cloud.github.io/categories/%E7%A7%91%E7%A0%94/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB/"/>
    
    
      <category term="论文" scheme="https://lulu-cloud.github.io/tags/%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>加密流量分类-论文1：Deep Learning for Encrypted Traffic Classification:An Overview</title>
    <link href="https://lulu-cloud.github.io/2022/08/30/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB-%E8%AE%BA%E6%96%871%EF%BC%9ADeep%20Learning%20for%20Encrypted%20Traffic%20Classification_%20An%20Overview/"/>
    <id>https://lulu-cloud.github.io/2022/08/30/加密流量分类-论文1：Deep Learning for Encrypted Traffic Classification_ An Overview/</id>
    <published>2022-08-30T13:27:14.000Z</published>
    <updated>2023-11-24T13:04:17.367Z</updated>
    
    <content type="html"><![CDATA[<h1 id="0、摘要"><a href="#0、摘要" class="headerlink" title="0、摘要"></a>0、摘要</h1><p>&emsp;&emsp;这是篇关于加密流量分类的综述，加密流量分类的入门之作，流量分类应用范围广泛，从isp的QoS提供和计费，到防火墙和入侵检测系统的安全应用。从最简单基于端口的、数据包检测到经典的机器学习方法，到由于深度学习的兴起，神经网络成为加密流量分类的主流。本文介绍了常用的深度学习方法及其在流量分类任务中的应用。然后讨论了开放的问题和它们的挑战。<br><strong>关键词：流量分类、深度学习、机器学习</strong></p><h1 id="1、介绍"><a href="#1、介绍" class="headerlink" title="1、介绍"></a>1、介绍</h1><p>简要介绍了加密流量分类方法的发展演变，具体如下：<br><strong>1.1 基于端口（port）的流量分类</strong></p><ul><li>优点：简单</li><li>缺点：该方法的准确性一直在下降，因为较新的应用程序要么使用众所周知的端口号来掩盖其流量，要么不使用标准的注册端口号。</li></ul><p><strong>1.2 基于有效载荷或数据包检验（data packet inspection：DPI）</strong><br>$\qquad$原理是不同类型的网络流量之中有特定的字符流（也称之为指纹），只需要在数据包的任意位置匹配这些字符流，从而进行分类。</p><ul><li>优点：简单快速，只需要检测网络流的前几个数据包。</li><li>缺点：方法仅适用于未加密的流量，且计算开销较大。</li></ul><p><strong>1.3 基于流量统计特征</strong><br>$\qquad$这些方法依赖于流量的统计或时间序列特性，能够处理加密和未加密的流量。通常采用经典的机器学习(ML)算法，如随机森林(RF)和k-最近邻(KNN)。</p><ul><li>优点：可以用于加密流量，不需解密。</li><li>缺点：依赖于人类的特征提取工程，开销大，耗时长。</li></ul><p><strong>1.4 基于深度学习方法</strong></p><ul><li>优点：深度学习可以通过训练自动选择特征，消除领域专家选择特征的需要，并且具有相当高的学习能力，因此可以学习高度复杂的模式，能够学习原始输入和相应输出之间的非线性关系，而不需要将问题分解为特征选择和分类的小子问题。</li><li>缺点：黑盒子，可解释性弱。</li></ul><h1 id="2、网络流量分类流程框架"><a href="#2、网络流量分类流程框架" class="headerlink" title="2、网络流量分类流程框架"></a>2、网络流量分类流程框架</h1><p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202308252141787.png" alt="通用的流量分类流程图"></p><h1 id="2-1-问题定义"><a href="#2-1-问题定义" class="headerlink" title="2.1 问题定义"></a>2.1 问题定义</h1><p>&emsp;&emsp;定义分类目标，从哪个领域分类。如nlp中文本分类，一大段关于某个电影的评论文本，可以是情感分类的角度出发分为积极、消极、中性，也可以是影评的类型出发分为关于内容的评论、关于电影演员演技的评论、关于电影启示的评论等等。流量分类分类中，具体的，可以如下：</p><ul><li>关于网络协议：流量是何种协议</li><li>关于应用程序：流量是何种app中的</li><li>关于流量类型：流量是干什么的，如浏览，视频等等</li><li>关于网站</li><li>关于用户行为：用户是干什么导致此种流量产生</li><li>关于浏览器</li><li>关于操作系统</li></ul><p>还可以分为：</p><ul><li>在线分类：要求实时性</li><li>离线分类</li></ul><h2 id="2-2-数据收集"><a href="#2-2-数据收集" class="headerlink" title="2.2 数据收集"></a>2.2 数据收集</h2><p>&emsp;&emsp; 对于大多数与流量相关的分类问题，还没有一个公认的数据集。可能的原因包括:</p><p> 1)可能的流量类别数量巨大，一个数据集几乎不可能包含所有的流量类型;<br> 2)没有普遍接受的数据收集和标记方法;<br> 3)不同的收集方法和场景导致不同的特征可用性和分布。</p><h2 id="2-3-数据集预处理"><a href="#2-3-数据集预处理" class="headerlink" title="2.3 数据集预处理"></a>2.3 数据集预处理</h2><ul><li>在网络环境中，包重发、重复ack和无序包可能会改变应用程序的流量模式，需要<strong>去重</strong>。</li><li>另一个对深度学习方法性能至关重要的预处理步骤是<strong>数据归一化</strong> 。在这一步中，所有的输入特征都被缩放到[0,1]范围内的值。使得梯度下降计算时收敛更快，并均衡所有特征的重要性。</li></ul><h2 id="2-4-流量特征"><a href="#2-4-流量特征" class="headerlink" title="2.4 流量特征"></a>2.4 流量特征</h2><ul><li>时间序列（Time Series）：报文长度、到达时间和连续报文的方向等等。[加密依旧可用]</li><li>头部（Header）</li><li>负载数据（Payload Data）</li><li>统计特征（Statistical Features）：平均包长度、最大包长度、最小到达间隔时间等等。[加密依旧可用]</li></ul><h1 id="3-深度学习技术"><a href="#3-深度学习技术" class="headerlink" title="3 深度学习技术"></a>3 深度学习技术</h1><h2 id="3-1-多层感知机（MLP）"><a href="#3-1-多层感知机（MLP）" class="headerlink" title="3.1 多层感知机（MLP）"></a>3.1 多层感知机（MLP）</h2><p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202308252142549.png" alt="MLP结构"><br>一般输入的特征映射至高维，后面逐渐降为到输出类别的维度，层之间一般为全连接（Fully Connected，FC）</p><h2 id="3-2-卷积神经网络（CNN）"><a href="#3-2-卷积神经网络（CNN）" class="headerlink" title="3.2 卷积神经网络（CNN）"></a>3.2 卷积神经网络（CNN）</h2><p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202308252142420.png" alt="CNN结构"><br>卷积提取特征，池化降低数据量，一般通过若干个卷积与池化操作后，将向量展平通过一到两个FC层后映射到输出类别的维度。<br>CNN的三大特性：</p><ul><li>局部连接（感受野）</li><li>权重共享（卷积）</li><li>空间或时间上的下采样（池化）</li></ul><p>一般方法：</p><ul><li>一维向量表示一个流（flow）或者会话（session），截取前N个字节数据，作为CNN的输入</li><li>将网络流量的时序数据转换为二维图像，作为CNN的输入</li></ul><h2 id="3-3-循环神经网络（RNN）"><a href="#3-3-循环神经网络（RNN）" class="headerlink" title="3.3 循环神经网络（RNN）"></a>3.3 循环神经网络（RNN）</h2><p>在深度学习中，一般会使用RNN的两个变体：</p><ul><li>长短期记忆网络（LSTM）</li><li>循环门控单元（GRU）<br>RNN擅长处理序列数据，这两种变体解决了传统RNN的梯度消失或者梯度爆炸的问题,<br>&emsp;&emsp;在流量分类上，混合模型（CNN+LSTM）优于纯LSTM或CNN模型。为了同时捕捉流的空间和时间特征，一些研究同时使用了CNN和RNN。</li></ul><h2 id="3-4-自编码器（AE）"><a href="#3-4-自编码器（AE）" class="headerlink" title="3.4 自编码器（AE）"></a>3.4 自编码器（AE）</h2><p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202308252142857.png" alt="AE"></p><ul><li>编码器将输入特征映射到一个低维空间。</li><li>解码器的目标则是将此低维向量解码成与原输入相近的特征。</li></ul><p>&emsp;&emsp;由此，低维向量中则“蕴含”了原先高维输入的所有信息，达到了抓住高维复杂信息的本质作用。AE是一种无监督学习方法，AE也有许多变体，如<br>去噪自编码器(DAEs)，通过提取损坏的样本来迫使模型学习更健壮的特征，从而输出完整的输入样本。<br>变分自编码器(VAEs)，旨在从目标分布生成虚拟样本。<br>可以叠加深层的，称为堆叠自动编码器(SAE)</p><h2 id="3-5-对抗生成网络（GAN）"><a href="#3-5-对抗生成网络（GAN）" class="headerlink" title="3.5 对抗生成网络（GAN）"></a>3.5 对抗生成网络（GAN）</h2><p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202308252142136.png" alt="GAN"></p><p>&emsp;&emsp;GAN是一种无监督技术，它同时训练生成模型和判别模型。</p><ul><li>生成器（Generator）旨在生成目标分布的(假)样例，“骗过”鉴别器。输入一般为高斯分布的随机噪声，输出一个生成伪样本。</li><li>鉴别器（Discriminator）模型旨在区分真实数据和生成数据。输入为真实样本与伪样本，判定真是样本与伪样本的真实性，如果鉴别器无力辨别真假，则模型<strong>可能</strong>收敛。<br>&emsp;&emsp;这两个模型通常都是神经网络。首先通过鉴别器训练生成器，使其误差概率最大化。然后，固定生成器，训练鉴别器，使输入真实数据和生成数据的误差概率最小。这个过程一直持续到它收敛为止。</li></ul><p>&emsp;&emsp;<strong>生成模型可用于处理网络流量分类中数据集的不平衡问题。不平衡问题指的是每个类别的样本数量差异很大的情况。</strong></p><h2 id="3-6-模型选择"><a href="#3-6-模型选择" class="headerlink" title="3.6 模型选择"></a>3.6 模型选择</h2><p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202308252142325.png" alt="在这里插入图片描述"></p><ul><li>特征选择直接影响神经网络输入结构和维度，这些维度影响计算复杂度和用于分类的数据包数量(内存复杂度)。</li><li>根据所选择的特征选择合适的模型</li></ul><h3 id="3-6-1-时间序列（Time-Series）-报头（Header）"><a href="#3-6-1-时间序列（Time-Series）-报头（Header）" class="headerlink" title="3.6.1 时间序列（Time Series）+报头（Header）"></a>3.6.1 时间序列（Time Series）+报头（Header）</h3><p>&emsp;<strong>时间序列特性几乎不受加密的影响</strong>，基本经典的ML算法与MLP都可以适用，当然CNN等模型可以获得更好的效益与更好的结果。</p><h3 id="3-6-2-负载（playload）-报头（Header）"><a href="#3-6-2-负载（playload）-报头（Header）" class="headerlink" title="3.6.2 负载（playload）+报头（Header）"></a>3.6.2 负载（playload）+报头（Header）</h3><p>&emsp;在当前加密的通信中，前几个包含握手信息的包通常是未加密的，它们已经成功地用于分类。但是负载中包含大量字节，导致数据维度较高，传统的ML与MLP不能很好适用，一般使用<strong>CNN或者CNN与LSTM</strong>结合的模型进行流量分类。</p><h3 id="3-6-3-统计特征（Statistical-Features）"><a href="#3-6-3-统计特征（Statistical-Features）" class="headerlink" title="3.6.3 统计特征（Statistical Features）"></a>3.6.3 统计特征（Statistical Features）</h3><p>&emsp;<strong>统计特征的数量是有限的，因此输入维度也是有限的</strong>。因此，大多数论文对这些特征使用了经典的ML方法，或在少数情况下使用MLP方法。<br>&emsp;虽然大多数研究通过观察整个流程来获得统计特征，但研究表明，根据数据集和统计特征的选择，<strong>从前10到180个数据包中获得统计特征可能足以进行分类</strong>。<br><strong>不适合在线快速分类</strong>，因为它需要捕获足够多的数据包来从一个流中获得可靠的统计特征。</p><h2 id="3-7-训练与验证"><a href="#3-7-训练与验证" class="headerlink" title="3.7 训练与验证"></a>3.7 训练与验证</h2><p>&emsp;&emsp;通常，数据集被分为三个独立的集:训练集、验证集和测试集。该模型在训练集上进行训练，通过观察验证集的准确性来调整模型的超参数。最后利用测试集得到了无偏精度。<br>&emsp;&emsp;简言之，<strong>训练集上进行梯度下降更新模型参数，验证集上选择最优超参数组合，测试集上进心模型评估。</strong></p><h2 id="3-8-定期评估-更新"><a href="#3-8-定期评估-更新" class="headerlink" title="3.8 定期评估/更新"></a>3.8 定期评估/更新</h2><p>&emsp;&emsp;在大多数与网络相关的应用程序中，流量在变化，依此<strong>流量特性总是在变化的</strong>。因此需要更新模型，增加模型分类普适性、健壮性。</p><h1 id="4-开放机遇与挑战"><a href="#4-开放机遇与挑战" class="headerlink" title="4 开放机遇与挑战"></a>4 开放机遇与挑战</h1><h2 id="4-1-更强大的加密协议"><a href="#4-1-更强大的加密协议" class="headerlink" title="4.1 更强大的加密协议"></a>4.1 更强大的加密协议</h2><p>&emsp;&emsp;例如关于QUIC和TLS 1.3协议的流量分类，还没有得到很好的研究。以往对TLS 1.2的研究主要使用握手时的纯文本字段。但是，通过在TLS 1.3和QUIC中引入0-RTT连接，第一个包中只有少数字段保持未加密，不清楚它们是否足以用于分类。</p><h2 id="4-2-多标签分类"><a href="#4-2-多标签分类" class="headerlink" title="4.2 多标签分类"></a>4.2 多标签分类</h2><p>&emsp;&emsp;单个流可以包含多个类标签，称为多路复用流。最困难的挑战是<strong>如何适当地收集和标记这些多标签流量</strong>。</p><h2 id="4-3-中间流分类？（Middle-Flow-Classification）"><a href="#4-3-中间流分类？（Middle-Flow-Classification）" class="headerlink" title="4.3 中间流分类？（Middle Flow Classification）"></a>4.3 中间流分类？（Middle Flow Classification）</h2><p>&emsp;&emsp;目前大部分的流量分类就是基于流的前几个数据包，因此，ISP需要存储所有流的前几个数据包，空间负担重。如果可以基于流中间的几个数据包，那么ISP就可以等待并且检测<strong>大象流（elephant flow）</strong>，然后捕获流中间的几个数据包进行分类，<strong>能减少内存和计算开销</strong>。</p><p>关于大象流、老鼠流：</p><ul><li>大象流（elephant flow）：大象流是通过网络链路进行大量的，持续的传递数据的过程。</li><li>老鼠流（mouse flow）：老鼠流是通过网络链路进行少量的，短时间的数据传递过程。</li></ul><p>&emsp;发邮件，看网页，聊微信，这些都属于老鼠流。而虚机的迁移，数据的迁移，MapReduce等等，属于大象流。 </p><h2 id="4-4-零日应用问题（Zero-day-Application）"><a href="#4-4-零日应用问题（Zero-day-Application）" class="headerlink" title="4.4 零日应用问题（Zero-day Application）"></a>4.4 零日应用问题（Zero-day Application）</h2><p>&emsp;零日应用是指新的流量类，它们的样本不存在于训练集中。已经表明，在某些情况下，零日应用程序可以在网络流量中占60%的流量和30%的字节。最近只有少数[14]研究提出了解决方案，通常依赖于检测未标记的簇，然后对它们进行标记。在ML社区中，主动学习(由模型选择哪些数据点应该被标记)已经被研究了多年。（聚类算法）</p><p>在最近一项对图像分类的研究中，强化学习和LSTM的结合被用于执行两种可能的操作之一:<strong>预测类别或要求一个新标签</strong>。</p><h2 id="4-5-迁移学习与领域自适应"><a href="#4-5-迁移学习与领域自适应" class="headerlink" title="4.5 迁移学习与领域自适应"></a>4.5 迁移学习与领域自适应</h2><p>&emsp;&emsp;收集到足够大的代表性数据集是不容易的，通常<strong>更容易获得为其他任务捕获的大型数据集</strong>，这可能有助于模型提取公共特征。此外，训练一个深度模型通常耗费时间长，而对<strong>模型进行再训练通常收敛更快</strong>，因此最好是对已经为类似任务进行过训练的模型进行再训练。</p><ul><li>迁移学习允许在源任务上训练的模型用于不同的目标任务，并且假设源任务与目标任务输入分布相似。</li><li>领域自适应处理的是任务相同，但源和目标的输入分布不同的情况。</li></ul><h2 id="4-6-多任务学习"><a href="#4-6-多任务学习" class="headerlink" title="4.6 多任务学习"></a>4.6 多任务学习</h2><p>&emsp;&emsp;一个模型中<strong>有一个以上的损失函数被优化</strong>。研究表明，即使对于单任务问题，增加一些辅助任务也可以提高泛化能力和性能。然而，对于网络流量分类任务还没有进行过研究。可能有很多方法可以定义辅助任务，而不需要额外的标记。多任务学习在网络流量分类中的有效性还没有得到研究。</p><p>第一次写论文博客，很水，写给自己看顺便总结一下，如有理解错误的地方，谢谢指正。</p><ul><li>参考：<br>[1].S. Rezaei and X. Liu, “Deep Learning for Encrypted Traffic Classification: An Overview,” in IEEE Communications Magazine, vol. 57, no. 5, pp. 76-81, May 2019, doi: 10.1109/MCOM.2019.1800819.<br>[2].大象流老鼠流的解释：<a href="https://www.zhihu.com/question/50171430">https://www.zhihu.com/question/50171430</a><br>[3].王茂南. 基于深度学习的加密流量识别技术研究[D].北京邮电大学,2021.DOI:10.26969/d.cnki.gbydu.2021.000480.</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;0、摘要&quot;&gt;&lt;a href=&quot;#0、摘要&quot; class=&quot;headerlink&quot; title=&quot;0、摘要&quot;&gt;&lt;/a&gt;0、摘要&lt;/h1&gt;&lt;p&gt;&amp;emsp;&amp;emsp;这是篇关于加密流量分类的综述，加密流量分类的入门之作，流量分类应用范围广泛，从isp的QoS提供和计
      
    
    </summary>
    
      <category term="科研" scheme="https://lulu-cloud.github.io/categories/%E7%A7%91%E7%A0%94/"/>
    
      <category term="加密流量分类" scheme="https://lulu-cloud.github.io/categories/%E7%A7%91%E7%A0%94/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB/"/>
    
    
      <category term="论文" scheme="https://lulu-cloud.github.io/tags/%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
</feed>
