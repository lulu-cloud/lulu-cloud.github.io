<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hexo</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://lulu-cloud.github.io/"/>
  <updated>2023-11-24T03:18:04.333Z</updated>
  <id>https://lulu-cloud.github.io/</id>
  
  <author>
    <name>lulu-cloud</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>疯狂的横向-开题期间</title>
    <link href="https://lulu-cloud.github.io/2023/11/23/%E5%BC%80%E9%A2%98%E3%80%81%E7%A7%91%E7%A0%94%E4%B8%8E%E6%A8%AA%E5%90%91/"/>
    <id>https://lulu-cloud.github.io/2023/11/23/开题、科研与横向/</id>
    <published>2023-11-23T13:42:14.000Z</published>
    <updated>2023-11-24T03:18:04.333Z</updated>
    
    <content type="html"><![CDATA[<ol><li>狠狠滴看各自论文，编开题报告！！</li><li>横向横向横向，每次会议的主题。无语辣。</li><li>听首歌，只想那种积极的，听得我爽就好，邓紫棋的《再见》</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ol&gt;
&lt;li&gt;狠狠滴看各自论文，编开题报告！！&lt;/li&gt;
&lt;li&gt;横向横向横向，每次会议的主题。无语辣。&lt;/li&gt;
&lt;li&gt;听首歌，只想那种积极的，听得我爽就好，邓紫棋的《再见》&lt;/li&gt;
&lt;/ol&gt;

      
    
    </summary>
    
      <category term="硕士生活" scheme="https://lulu-cloud.github.io/categories/%E7%A1%95%E5%A3%AB%E7%94%9F%E6%B4%BB/"/>
    
    
      <category term="吐槽" scheme="https://lulu-cloud.github.io/tags/%E5%90%90%E6%A7%BD/"/>
    
  </entry>
  
  <entry>
    <title>加密流量分类-论文3:FS-Net_ A Flow Sequence Network For Encrypted Traffic Classification</title>
    <link href="https://lulu-cloud.github.io/2023/08/26/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB-%E8%AE%BA%E6%96%873%EF%BC%9AFS-Net_%20A%20Flow%20Sequence%20Network%20For%20Encrypted%20Traffic%20Classification/"/>
    <id>https://lulu-cloud.github.io/2023/08/26/加密流量分类-论文3：FS-Net_ A Flow Sequence Network For Encrypted Traffic Classification/</id>
    <published>2023-08-26T13:27:14.000Z</published>
    <updated>2023-11-24T03:18:04.331Z</updated>
    
    <content type="html"><![CDATA[<h1 id="0、摘要"><a href="#0、摘要" class="headerlink" title="0、摘要"></a>0、摘要</h1><p> &emsp;&emsp;FS-Net是一个端到端的分类模型，它从原始流中学习代表性特征，然后在一个统一的框架中对它们进行分类。采用多层编码器-解码器结构，可以深入挖掘流的潜在序列特征，并引入重构机制，提高特征的有效性。</p><h1 id="1、问题引入"><a href="#1、问题引入" class="headerlink" title="1、问题引入"></a>1、问题引入</h1><p> &emsp;&emsp;传统的基于统计特征加上机器学习的流量分类，太依赖与专业经验，即人类的特征工程，特征工程的好坏直接影响分类性能。以往的基于DL的流量分类方法如<a href="https://blog.csdn.net/qq_45125356/article/details/126661237?spm=1001.2014.3001.5501">Deep Packet:</a>，只使用了网络流量的有效载荷进行分类，没有考虑到流量中的其他信息。因此提出基于DL的端到端的分类模型，尝试设计一种新的适合<strong>流序列特征</strong>的神经网络结构，可以直接从原始输入中学习特征，学习到的特征以真实标签为指导，从而提高性能。因此，它可以节省设计和验证功能的人力。</p><h1 id="2、问题定义"><a href="#2、问题定义" class="headerlink" title="2、问题定义"></a>2、问题定义</h1><ul><li>FS-Net是基于网络流量的应用分类，即应用识别。</li><li><p>一个原始流量可以表示为不同的类型序列，如消息类型序列或者<strong>包长度序列</strong>，本文将一个原始流量看作包长度序列。具体的，Xp表示第p个样本的序列表示：<br>$$<br>X_p=[L_1^p,L_2^p,…,L_n^p)]<br>$$<br>其中n是Xp的长度，L~i~^p^是时间步长i的数据包值。</p><h1 id="3、模型结构"><a href="#3、模型结构" class="headerlink" title="3、模型结构"></a>3、模型结构</h1><h2 id="3-1总览"><a href="#3-1总览" class="headerlink" title="3.1总览"></a>3.1总览</h2><p>类似于AE半监督的思想，模型由五大块组成</p><ul><li>嵌入层</li><li>编码层</li><li>解码层</li><li>重构层</li><li>分类器<br><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311241039729.png" alt="模型整体结构"></li></ul><h2 id="3-2-嵌入层"><a href="#3-2-嵌入层" class="headerlink" title="3.2 嵌入层"></a>3.2 嵌入层</h2><p>&emsp;&emsp;</p><ul><li>任务：将L~1~到L~n~的序列信息转化为e~1~到e~n~的向量表示。如果有K个数据，且嵌入向量的维度为d，那么K个数据经过嵌入层将转化为一个矩阵E^K*d^,矩阵E是可以在模型训练过程中训练出来的，矩阵的每一个行向量都对应着一个数据样本的嵌入向量表示。</li><li><p>使用嵌入向量的优点：</p><ol><li>一些非数值(如消息类型)可以很容易地表示为数值进行计算。</li><li>向量表示丰富了一个序列中每个元素保存的信息。嵌入向量的每个维度都是影响流生成的潜在特征。同一元素在不同的序列中可能有不同的含义和方面。</li><li>模型可以学习每个元素的嵌入向量的面向任务的较优秀的向量表示，从而提高分类性能。<h2 id="3-3-编码层"><a href="#3-3-编码层" class="headerlink" title="3.3 编码层"></a>3.3 编码层</h2></li></ol></li><li>输入为嵌入向量，输出压缩后的特征</li><li>编码采用的是堆叠的Bi-GRU神经网络模型。低层的编码器学习到局部特征，高层的编码器学习到相对全局的特征，最后将<strong>所有层的最终前向与后向的隐藏状态串联</strong>Z~e~作为编码器压缩后的特征。此时，Z~e~就包含了整个编码流程序列的双向上下文信息，将会作为分类器的输入的一部分。（既有局部的，又有全局的）<h2 id="3-4-解码层"><a href="#3-4-解码层" class="headerlink" title="3.4 解码层"></a>3.4 解码层</h2></li><li>解码器的结构如同编码器一样，为折叠的Bi-GRU网络结构。</li><li><p>输入为Z~e~，输出由两个部分组成</p><p> 1.第一部分类似于编码器的输出，为解码器所有层的前向状态与后向状态的拼接，称之为，Z~d~这部分输出将会作用与最终的分类器输出的一部分。<br> 2.第二部分则是最后一层解码器的自身输出，这部分将会送入重构层，进行重构，重构目标是还原起初的模型输入。</p><h2 id="3-5-分类器"><a href="#3-5-分类器" class="headerlink" title="3.5 分类器"></a>3.5 分类器</h2></li></ul></li><li>分类器之前，设置了<strong>Dense层</strong>对分类器的输入（即Z~e~与Z~d~向量的拼接）进行压缩，得到新的特征向量z.<br><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311241039676.png" alt="压缩公式"><br>然而，z的维度还是太高，使用两层带Selu的激活函数的MLP对z进行降维得到Z~c~,降维过后能有效避免过拟合问题。<br><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311241039822.png" alt="降维"><br>公式中的W1，b1,b2都是可以学习的参数。</li><li>输入为Z~c~，经过softmax分类器，得到预测标签A^-^，与真实标签A之间构造一个交叉熵损失L~C~</li><li>在重构器后面，解码器中的Bi-GRU经过重构，输出的L~i^~与原始的输入特征L~i~之间可以构造另外一个交叉熵损失L~R~</li><li><p>因此，最终的损失函数<br>$$<br>L=L_C+αL_R<br>$$<br>α是超参数。</p><h1 id="4、实验"><a href="#4、实验" class="headerlink" title="4、实验"></a>4、实验</h1><ul><li><strong>实验设置</strong>：以报文长度序列作为FS-Net的输出，嵌入向量维度d设置为128，GRU的隐藏状态维度也是128，α设置为1，dropout设置为0.3，Adam优化器的lr设置为0.0005</li><li><strong>与其他模型结果实验对比的结论</strong>：加密流分类任务中，报文长度比消息类型更具有代表性。主要原因可能是[11]发现的不同应用程序的消息类型序列高度重叠。有更多的信息蕴含在包长度集合中而不是消息类型的集合中。</li><li><p><strong>对FS-Net的一些分析</strong>：</p><ol><li>摒弃解码器层、重构层和重构损失，即只将基于编码器的特征向量Z~e~传递到密集层进行分类。该变体称为FS-ND.此时FS-Net与其变体FS-ND的默认输入仍旧为<strong>包长度序列（The packet length sequence）</strong>。<blockquote><p>个人感觉这种变体特别像BERT，BERT就是只使用了Transformer的编码器结构，经历预训练后，在诸多下游任务中均获得了不错的效果。当然，BERT是有MLM与NSP的预训练任务的，而此处的FS-ND貌似并没有提及，只是单纯砍掉了解码器与重构器那一部分。</p></blockquote></li><li>因为传统的消息类型马尔可夫方法(FoSM、SOCRT、SOB)以<strong>消息类型序列（The message type sequences）</strong>作为输入。为了便于比较，FS-Net和FS-ND也结合消息类型序列进行测试，对应的方法记为FS-Net- s和FS-ND- s。</li><li>采用多属性序列(消息类型序列和报文长度序列)来提高性能。即同时关注<strong>包长度序列（The packet length sequence）</strong>与<strong>消息类型序列（The message type sequences）</strong>，这两种不同的模型被称为FS-Net-SL和FS-ND-SL。<br><img src="https://img-blog.csdnimg.cn/51ff895315324d16b5adc84b28e2dbbb.png" alt="实验结构"></li></ol><ul><li><strong>结果分析</strong>：<ol><li><strong>重构机制（即包含解码层、重构层）有用</strong>，提高分类性能。与不同序列比较，FS-Net的FTF性能始终优于FS-ND，提高了0.01左右。利用重构机制，引导从编码器学习到的特征存储更丰富的信息。</li><li><strong>重构机制有用，但是对比FS-ND提示不大，并且加了那么多结构，有点不太划算</strong>。变体模型FS-ND也优于现有的模型，而且FS-Net和FS-ND之间的性能差距不大。然而，FS-ND模型比FS-Net需要更少的层，可以更快地训练。</li><li><strong>报文长度序列的信息比消息类型序列的信息更丰富</strong>。消息类型序列的信息几乎被合并到包长度序列中。从FS-Net到FS-Net- sl的改进不显著(如FTF为0.0005)。FSND和FS-ND-SL之间也存在类似的现象。</li></ol></li></ul></li></ul></li><li><p><strong>调参分析</strong>：</p><ol><li><strong>GRU的隐藏状态维度</strong>：太大，模型冗余，过拟合的同时容易从噪声中学习无用信息；太小，不足以提取数据的隐藏特征。研究中设置为128。</li><li><strong>超参数α</strong>：建议α值设为[0.125,2]。<h1 id="5、总结与思考"><a href="#5、总结与思考" class="headerlink" title="5、总结与思考"></a>5、总结与思考</h1></li></ol></li><li>模型结构，类似与NLP中的Seq2Seq结构，可否在中间的编码器与解码器之间照葫芦画瓢加上Attention机制来进一步优化捏？</li><li>去除解码器与重构器，模型复杂度减少，并且实验证明在数据集上的表现FS-ND也跟FS-Net差之无几，能否在FS-ND上做出改进，使之效率与复杂度要比现在的模型好。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;0、摘要&quot;&gt;&lt;a href=&quot;#0、摘要&quot; class=&quot;headerlink&quot; title=&quot;0、摘要&quot;&gt;&lt;/a&gt;0、摘要&lt;/h1&gt;&lt;p&gt; &amp;emsp;&amp;emsp;FS-Net是一个端到端的分类模型，它从原始流中学习代表性特征，然后在一个统一的框架中对它们进行分
      
    
    </summary>
    
      <category term="加密流量分类" scheme="https://lulu-cloud.github.io/categories/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB/"/>
    
    
      <category term="论文" scheme="https://lulu-cloud.github.io/tags/%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>加密流量分类-论文2:Deep Packet_ A Novel Approach For Encrypted Traffic Classification Using Deep Learning</title>
    <link href="https://lulu-cloud.github.io/2023/08/25/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB-%E8%AE%BA%E6%96%872%EF%BC%9ADeep%20Packet_%20A%20Novel%20Approach%20For%20Encrypted%20Traffic%20Classification%20Using%20Deep%20Learning/"/>
    <id>https://lulu-cloud.github.io/2023/08/25/加密流量分类-论文2：Deep Packet_ A Novel Approach For Encrypted Traffic Classification Using Deep Learning/</id>
    <published>2023-08-25T13:27:14.000Z</published>
    <updated>2023-11-24T03:18:04.338Z</updated>
    
    <content type="html"><![CDATA[<h1 id="0、摘要"><a href="#0、摘要" class="headerlink" title="0、摘要"></a>0、摘要</h1><p>&emsp;&emsp;论文提出的方案称为“深度包”(deep packet)，可以处理网络流量分类为主要类别(如FTP和P2P)的流量表征，以及需要终端用户应用程序(如BitTorrent和Skype)识别的应用程序识别。与现有的大多数方法不同，深度报文不仅可以识别加密流量，还可以区分VPN网络流量和非VPN网络流量。网络架构基于CNN与SAE，能同时进行<strong>应用识别</strong>与<strong>流量类型</strong>的分类任务。</p><h1 id="1、介绍"><a href="#1、介绍" class="headerlink" title="1、介绍"></a>1、介绍</h1><p>&emsp;&emsp;准确的流量分类已成为提供适当的服务质量(quality of service, QoS)、异常检测等高级网络管理任务的先决条件之一。流量分类在与网络管理相关的学术界和工业界都引起了极大的兴趣。</p><p>&emsp;&emsp;本文贡献：</p><ul><li>在Deep Packet中，不需要专家来提取与网络流量相关的特征。这种方法省去了查找和提取特征的繁琐步骤。（只要是基于DL的方法都能做到这一点）</li><li>Deep Packet可以在两个粒度级别(应用程序识别和流量表征)上识别流量，并获得最先进的结果。</li><li><p>深度数据包可以准确地分类最难的一类应用程序，已知是P2P。</p><h1 id="2、相关工作"><a href="#2、相关工作" class="headerlink" title="2、相关工作"></a>2、相关工作</h1><p>&emsp;&emsp;等于是一个综述，概览了之前流量分类的一些方法以及它的适用性与优缺点。可以参考<a href="https://blog.csdn.net/qq_45125356/article/details/126592812?spm=1001.2014.3001.5502">论文解读1</a></p></li><li><p>Port-based approach（基于端口）：提取过程简单，端口号不受加密方案的影响。然而，端口混淆、网络地址转换(NAT)、端口转发、协议嵌入和端口随机分配的普遍存在大大降低了这种方法的准确性，<strong>目前已经不适用</strong>。</p></li><li>Payload Inspection Techniques（基于有效载荷）:即深度包检测（DPI）。</li><li>Statistical and machine learning approach（基于统计特征+机器学习方法）：这些方法依赖于流量的统计或时间序列特性，能够处理加密和未加密的流量。</li></ul><p>&emsp;&emsp;<strong>总之，以前的方法，特征提取阶段依赖于人类的特征工程，耗时、昂贵且出错率高。</strong></p><h1 id="3、深度学习背景"><a href="#3、深度学习背景" class="headerlink" title="3、深度学习背景"></a>3、深度学习背景</h1><p>&emsp;&emsp;依旧是综述，关于神经网络的。这里主要介绍了两种神经网络结构。</p><h2 id="3-1-自编码器（Autoencoder，AE）"><a href="#3-1-自编码器（Autoencoder，AE）" class="headerlink" title="3.1 自编码器（Autoencoder，AE）"></a>3.1 自编码器（Autoencoder，AE）</h2><p>&emsp;&emsp;AE是一种无监督框架。考虑一个训练集{x1, x2，…， xn}其中对于每个训练数据我们有xi∈Rn。自编码器目标定义为yi = xi，对于i∈{1,2，…， n}，即网络的输出等于输入。自动编码器试图学习数据集的压缩表示，即<strong>将高维数据通过编码器降维，然后降维后的数据通过解码器升维，输出尽量与输入相同。这样。降维后的数据则包含了原始输入数据的信息</strong>。一般地，编码器与解码器的结构都是对称的。<br><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311011127286.png" alt="AE结构"><br>&emsp;&emsp;在实践中，为了获得更好的性能，一般使用<strong>堆栈式自动编码器(SAE)</strong>。将多个自动编码器堆叠起来，每个编码器的输出都是连续层的输入，而连续层本身就是一个自动编码器。堆叠式自动编码器的训练过程采用贪婪的分层方式完成。首先，该方法训练网络的每一层，同时冻结其他层的权值。在训练完所有层之后，为了得到更准确的结果，对整个神经网络进行微调。在微调阶段，利用反向传播算法调整各层权重。此外，对于分类任务，可以在最后一层应用额外的softmax层。<br><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311011127399.png" alt="SAE"></p><h2 id="3-2-卷积神经网络-Convolutional-Neural-Network-CNN"><a href="#3-2-卷积神经网络-Convolutional-Neural-Network-CNN" class="headerlink" title="3.2 卷积神经网络(Convolutional Neural Network, CNN)"></a>3.2 卷积神经网络(Convolutional Neural Network, CNN)</h2><ul><li>卷积：进行特征抽取</li><li>池化：聚合低级特征，获得局部不变性，并且能降低网络训练与测试的参数量。<br>&emsp;&emsp;一维卷积神经网络（1D-CNNs）可以捕获网络数据包中相邻字节之间的空间依赖关系，从而找到每一类协议/应用程序的区别模式，从而对流量进行准确的分类。<h1 id="4、方法"><a href="#4、方法" class="headerlink" title="4、方法"></a>4、方法</h1><h2 id="4-1-数据集"><a href="#4-1-数据集" class="headerlink" title="4.1 数据集"></a>4.1 数据集</h2>&emsp;&emsp;<strong>ISCX VPN-nonVPN</strong>：该数据集实在数据链路层捕获的，因此，每个数据包都包含一个以太网报头、一个IP数据报报头、一个TCP/UDP报头。</li></ul><h2 id="4-2-预处理"><a href="#4-2-预处理" class="headerlink" title="4.2 预处理"></a>4.2 预处理</h2><ol><li>删除以太网报头</li><li>将UDP报头填充0至20字节长度（TCP通常具有20字节长度的报头，而UDP具有8字节长度的报头。为了使传输层的段一致，在UDP段的报头末尾注入0，使它们的长度与TCP报头相等）</li><li>屏蔽IP数据报报头的IP</li><li>删除不相关的数据包，例如没有负载的数据包（TCP握手时SYN、ACK设置为1以及FIN设置为1的数据包）或者DNS数据段（将url转为IP地址的）</li><li>将原始数据包转为字节向量</li><li>截断超过1500的向量，不足1500长度的填充0</li><li>将向量的每个元素除以255来规范化字节向量</li><li>针对样本不均衡问题，对样本更多的类进行欠采样，直到类相对平衡。<br><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311011127411.png" alt="每个类别中的样本数量"><h2 id="4-3-网络架构"><a href="#4-3-网络架构" class="headerlink" title="4.3 网络架构"></a>4.3 网络架构</h2><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311011127926.png" alt="Deep Packet网络架构"></li></ol><ul><li>关于SAE的部分：<br>由五个全连接层（FC）,分别由400、300、200、100和50个神经元组成。为防止过拟合问题，每层后采用dropout技术，dropout率为0.05。针对应用识别和流量表征任务，在SAE的最后一层，分别添加了一个包含17个神经元和12个神经元的softmax分类器。</li><li>关于CNN的部分：<br>包括两个连续的卷积层，然后是池化层。将二维张量压缩为一维矢量，并将其送入三层全连接神经元网络，该网络采用dropout技术以避免过拟合。最后，将类似于SAE架构的softmax分类器应用于分类任务。<br><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311011128167.png" alt="CNN架构"><br>CNN的超参数如下：<br><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311011128738.png" alt="CNN的超参数"><h1 id="5、实验"><a href="#5、实验" class="headerlink" title="5、实验"></a>5、实验</h1></li><li>对于CNN的调参，此处改变了两个卷积层的滤波器大小、滤波器数量和步幅。总共评估了116个应用识别和交通表征任务的加权平均F1分数模型。通过结果得出如下结论：<strong>对于流量分类任务，无法选择最优模型，因为“最优模型”的定义是不明确的，而且模型的精度和它的复杂性(即训练速度和测试速度)之间存在权衡</strong>。</li><li><strong>增加神经网络的复杂度并不一定会带来更好的性能</strong>。可能的原因有：<br>&emsp;&emsp;一个复杂的模型在训练阶段更容易遇到梯度消失问题，从而导致模型的<strong>欠拟合</strong>。<br>&emsp;&emsp; 一个学习模型变得更复杂，而训练数据的大小保持不变，就会出现<strong>过拟合</strong>问题。</li><li>该工作与Wang W, Zhu M, Wang J, Zeng X, Yang Z (2017)<br>End-to-end encrypted traffic classification with one-dimensional convolution neural networks. In: Intel-ligence and Security Informatics (ISI), 2017 IEEE International Conference on, IEEE. 的方法类似，但Wang等人在流量表征的任务上获得了100%的精度，可能的原因是<strong>预处理过程中没有屏蔽IP地址字段，导致模型仅仅用IP地址这一特征来进行分类</strong>。</li></ul><h1 id="6、总结"><a href="#6、总结" class="headerlink" title="6、总结"></a>6、总结</h1><p><img src="https://raw.githubusercontent.com/lulu-cloud/lili_images/main/image/202311011128877.png" alt="总结"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;0、摘要&quot;&gt;&lt;a href=&quot;#0、摘要&quot; class=&quot;headerlink&quot; title=&quot;0、摘要&quot;&gt;&lt;/a&gt;0、摘要&lt;/h1&gt;&lt;p&gt;&amp;emsp;&amp;emsp;论文提出的方案称为“深度包”(deep packet)，可以处理网络流量分类为主要类别(如FTP和P
      
    
    </summary>
    
      <category term="加密流量分类" scheme="https://lulu-cloud.github.io/categories/%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%88%86%E7%B1%BB/"/>
    
    
      <category term="论文" scheme="https://lulu-cloud.github.io/tags/%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
</feed>
